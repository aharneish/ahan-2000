{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nimport os, importlib.util\n!pip install --upgrade -qqq uv\nif importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):    \n    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n    !uv pip install -qqq \\\n        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n        git+https://github.com/triton-lang/triton.git@0add68262ab0a2e33b84524346cb27cbb2787356#subdirectory=python/triton_kernels\nelif importlib.util.find_spec(\"unsloth\") is None:\n    !uv pip install -qqq unsloth\n!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:41:19.384584Z","iopub.execute_input":"2026-01-21T14:41:19.385258Z","iopub.status.idle":"2026-01-21T14:41:40.230216Z","shell.execute_reply.started":"2026-01-21T14:41:19.385216Z","shell.execute_reply":"2026-01-21T14:41:40.229455Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"datasets:\n\n1. DianaW/empathetic_dialogues\n2. Ashokajou51/ESConv_Original\n3. google-research-datasets/go_emotions","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nimport torch\nmax_seq_length = 1024\ndtype = None\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/gpt-oss-20b\",\n    dtype = dtype,\n    max_seq_length = max_seq_length,\n    load_in_4bit = True,\n    full_finetuning = False,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:31:18.971276Z","iopub.execute_input":"2026-01-20T14:31:18.971554Z","iopub.status.idle":"2026-01-20T14:33:35.923497Z","shell.execute_reply.started":"2026-01-20T14:31:18.971524Z","shell.execute_reply":"2026-01-20T14:33:35.922722Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2026-01-20 14:31:38.099125: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1768919498.514264      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1768919498.632678      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1768919499.667244      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768919499.667285      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768919499.667288      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1768919499.667290      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2026.1.3: Fast Gpt_Oss patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gpt_oss won't work! Using float32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c1edd833f16444b891d5683288b0463"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b41175ddcd426f881c86836cc1af4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c072c216b03c40e88addc0e3f3f946b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.37G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2062ca8442d44cdbef62e5d72e69a08"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db7a5f3c5ce343bfa94ad443a722d49f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73065e05792e4140b0e8e09fd7940df2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/165 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a5f9ff3bf6c4a9d9a72376567d6e246"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbe170d9f42d496eb3dac597d6ef5857"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5199430e1770476b8ee6b14fd227c381"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7ee09e5b8cb4472aa2d7185eb9eac5d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a49b2ffdbc7e409cabf4707d43f435e2"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 8,\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, \n    bias = \"none\",\n    use_gradient_checkpointing = \"unsloth\", \n    random_state = 3407,\n    use_rslora = False,\n    loftq_config = None,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:33:35.924856Z","iopub.execute_input":"2026-01-20T14:33:35.925595Z","iopub.status.idle":"2026-01-20T14:33:40.668407Z","shell.execute_reply.started":"2026-01-20T14:33:35.925563Z","shell.execute_reply":"2026-01-20T14:33:40.667515Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Making `model.base_model.model.model` require gradients\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"def formatting_prompts_func(examples):\n    convos = examples[\"messages\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\n\nfrom datasets import load_dataset\n\ndataset1 = load_dataset(\"DianaW/empathetic_dialogues\", split=\"train\")\ndataset2 = load_dataset(\"Ashokajou51/ESConv_Original\", split=\"train\")\ndataset3 = load_dataset(\"google-research-datasets/go_emotions\", split=\"train\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:08.372393Z","iopub.execute_input":"2026-01-21T14:44:08.373227Z","iopub.status.idle":"2026-01-21T14:44:17.500980Z","shell.execute_reply.started":"2026-01-21T14:44:08.373194Z","shell.execute_reply":"2026-01-21T14:44:17.500192Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/757 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d129994264754fc4b6b30332dc48c26d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/5.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fb83709f086434da52771b1efce11b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001.parquet:   0%|          | 0.00/604k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ac63008b864d61a8c9c46c0858edd0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/test-00000-of-00001.parquet:   0%|          | 0.00/608k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"323e75fd154346689c9ec5ea13c230aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/84169 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5829aebf1aa841c58151a34b7ffddfc1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/6340 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcac865e40fe457fb32cc5f1510f70ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5714 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4ea7d37325a412889e4d3898be030ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58c008f7826f4175837ceb89e3270e33"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ea10a5cdeac4625bc631e390ee491c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"valid.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0467da400a1452e870aa5b775e0a843"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"633cb2356be1496e9492a8728d8cb427"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1214 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f980f8b67ed4f6692bc354258c385d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a9770bc38694afc9b193d2d35d2688b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/195 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69e52371774a48278cbb78bf96aa2e36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8224c286cd9c45deadc0a29374795e8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"simplified/train-00000-of-00001.parquet:   0%|          | 0.00/2.77M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14c00568f4de4bf9a465ac4667b441cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"simplified/validation-00000-of-00001.par(â€¦):   0%|          | 0.00/350k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20df2ed0b0904caa9096c9dbe524fc4c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"simplified/test-00000-of-00001.parquet:   0%|          | 0.00/347k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f024a4a4fdb64bed88e619fb17d87b3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/43410 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bb419924cc9419a9bf22a5cfbeba04a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/5426 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6132adae8fce47f29c1c52c70a342bd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5427 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c0be4e824a046ba80fa7f8057e9e006"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def preprocess_ed(example):\n    user = example[\"prompt\"]\n    assistant = example[\"utterance\"]\n\n    text = f\"<user>{user}</user>\\n<assistant>{assistant}</assistant>\"\n\n    tokens = tokenizer(\n        text,\n        truncation=True,\n        padding=False\n    )\n\n    return {\n        \"input_ids\": tokens[\"input_ids\"],\n        \"labels\": tokens[\"input_ids\"].copy(),  # LM loss ON\n        \"emotion_label\": -100,\n        \"strategy_label\": -100\n    }\n\ndataset1 = dataset1.map(\n    preprocess_ed,\n    remove_columns=dataset1.column_names\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:17.502587Z","iopub.execute_input":"2026-01-21T14:44:17.502902Z","iopub.status.idle":"2026-01-21T14:44:43.122032Z","shell.execute_reply.started":"2026-01-21T14:44:17.502873Z","shell.execute_reply":"2026-01-21T14:44:43.121445Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/84169 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7c1e049b76d4a4ca9b3d931b961741f"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"STRATEGY_MAP = {\n    \"Question\": 0,\n    \"Reflection of feelings\": 1,\n    \"Restatement or Paraphrasing\": 2,\n    \"Providing Suggestions\": 3,\n    \"Affirmation and Reassurance\": 4,\n    \"Information\": 5,\n    \"Others\": 6\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:43.122994Z","iopub.execute_input":"2026-01-21T14:44:43.123261Z","iopub.status.idle":"2026-01-21T14:44:43.126978Z","shell.execute_reply.started":"2026-01-21T14:44:43.123235Z","shell.execute_reply":"2026-01-21T14:44:43.126379Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def preprocess_esconv(batch):\n    input_ids = []\n    labels = []\n    emotion_labels = []\n    strategy_labels = []\n\n    for dialog in batch[\"dialog\"]:\n        history = \"\"\n\n        for turn in dialog:\n            if turn[\"speaker\"] == \"usr\":\n                history += f\"<user>{turn['text']}</user>\\n\"\n\n            elif turn[\"speaker\"] == \"sys\":\n                strategy = turn.get(\"strategy\")\n                if strategy not in STRATEGY_MAP:\n                    continue\n\n                assistant = turn[\"text\"]\n                full_text = history + f\"<assistant>{assistant}</assistant>\"\n\n                tokens = tokenizer(\n                    full_text,\n                    truncation=True,\n                    padding=False\n                )\n\n                input_ids.append(tokens[\"input_ids\"])\n                labels.append(tokens[\"input_ids\"].copy())\n                emotion_labels.append(-100)\n                strategy_labels.append(STRATEGY_MAP[strategy])\n\n                history += f\"<assistant>{assistant}</assistant>\\n\"\n\n    return {\n        \"input_ids\": input_ids,\n        \"labels\": labels,\n        \"emotion_label\": emotion_labels,\n        \"strategy_label\": strategy_labels\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:43.128568Z","iopub.execute_input":"2026-01-21T14:44:43.128796Z","iopub.status.idle":"2026-01-21T14:44:43.254408Z","shell.execute_reply.started":"2026-01-21T14:44:43.128773Z","shell.execute_reply":"2026-01-21T14:44:43.253713Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset2 = dataset2.map(\n    preprocess_esconv,\n    batched=True,\n    remove_columns=dataset2.column_names\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:43.255294Z","iopub.execute_input":"2026-01-21T14:44:43.255618Z","iopub.status.idle":"2026-01-21T14:44:59.459311Z","shell.execute_reply.started":"2026-01-21T14:44:43.255583Z","shell.execute_reply":"2026-01-21T14:44:59.458658Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1214 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb76f7e4d35141a390d9a413a0e6fa0d"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def preprocess_goemotions(example):\n    tokens = tokenizer(\n        example[\"text\"],\n        truncation=True,\n        padding=False\n    )\n\n    return {\n        \"input_ids\": tokens[\"input_ids\"],\n        \"labels\": [-100] * len(tokens[\"input_ids\"]),  # ðŸš« LM loss OFF\n        \"emotion_label\": example[\"labels\"][0],         # single-label\n        \"strategy_label\": -100\n    }\n\ndataset3 = dataset3.map(\n    preprocess_goemotions,\n    remove_columns=dataset3.column_names\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:44:59.460380Z","iopub.execute_input":"2026-01-21T14:44:59.460750Z","iopub.status.idle":"2026-01-21T14:45:07.972989Z","shell.execute_reply.started":"2026-01-21T14:44:59.460719Z","shell.execute_reply":"2026-01-21T14:45:07.972444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/43410 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4bc747bce1384b33b41c0625b5220b6f"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"from datasets import Features, Sequence, Value\n\nUNIFIED_FEATURES = Features({\n    \"input_ids\": Sequence(Value(\"int64\")),\n    \"labels\": Sequence(Value(\"int64\")),\n    \"emotion_label\": Value(\"int64\"),\n    \"strategy_label\": Value(\"int64\"),\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:07.973965Z","iopub.execute_input":"2026-01-21T14:45:07.974233Z","iopub.status.idle":"2026-01-21T14:45:07.978522Z","shell.execute_reply.started":"2026-01-21T14:45:07.974208Z","shell.execute_reply":"2026-01-21T14:45:07.977778Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"dataset1 = dataset1.cast(UNIFIED_FEATURES)\ndataset2 = dataset2.cast(UNIFIED_FEATURES)\ndataset3 = dataset3.cast(UNIFIED_FEATURES)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:07.979516Z","iopub.execute_input":"2026-01-21T14:45:07.979746Z","iopub.status.idle":"2026-01-21T14:45:08.399433Z","shell.execute_reply.started":"2026-01-21T14:45:07.979722Z","shell.execute_reply":"2026-01-21T14:45:08.398548Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/84169 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5da1949cdbb14988a71c303f307452d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/15446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"803331ce18784258a68f4964acd26e20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/43410 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c4b62963a754ee9862f27f44ccc43da"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"dataset3","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:08.400381Z","iopub.execute_input":"2026-01-21T14:45:08.400744Z","iopub.status.idle":"2026-01-21T14:45:08.405370Z","shell.execute_reply.started":"2026-01-21T14:45:08.400718Z","shell.execute_reply":"2026-01-21T14:45:08.404588Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids', 'labels', 'emotion_label', 'strategy_label'],\n    num_rows: 43410\n})"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"from datasets import interleave_datasets\nimport numpy as np\n\ndatasets = [dataset1, dataset2, dataset3]\nsizes = np.array([len(d) for d in datasets])\n\nalpha = 0.7\nprobs = (sizes ** alpha) / (sizes ** alpha).sum()\n\nmixed_dataset = interleave_datasets(\n    datasets,\n    probabilities=probs.tolist(),\n    seed=42,\n    stopping_strategy=\"all_exhausted\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:57:33.046467Z","iopub.execute_input":"2026-01-21T09:57:33.046714Z","iopub.status.idle":"2026-01-21T09:57:38.929455Z","shell.execute_reply.started":"2026-01-21T09:57:33.046689Z","shell.execute_reply":"2026-01-21T09:57:38.928840Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"print(mixed_dataset.features)\nprint(mixed_dataset[0].keys())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:57:38.930418Z","iopub.execute_input":"2026-01-21T09:57:38.930748Z","iopub.status.idle":"2026-01-21T09:57:38.936187Z","shell.execute_reply.started":"2026-01-21T09:57:38.930714Z","shell.execute_reply":"2026-01-21T09:57:38.935432Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': List(Value('int64')), 'labels': List(Value('int64')), 'emotion_label': Value('int64'), 'strategy_label': Value('int64')}\ndict_keys(['input_ids', 'labels', 'emotion_label', 'strategy_label'])\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"# GoEmotions samples must NOT have LM loss\nassert any(\n    all(l == -100 for l in ex[\"labels\"]) and ex[\"emotion_label\"] != -100\n    for ex in mixed_dataset.select(range(500))\n)\n\n# ESConv samples must have strategy labels\nassert any(\n    ex[\"strategy_label\"] != -100\n    for ex in mixed_dataset.select(range(500))\n)\n\n# ED samples must have LM loss\nassert any(\n    any(l != -100 for l in ex[\"labels\"])\n    and ex[\"emotion_label\"] == -100\n    and ex[\"strategy_label\"] == -100\n    for ex in mixed_dataset.select(range(500))\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:57:38.937099Z","iopub.execute_input":"2026-01-21T09:57:38.937340Z","iopub.status.idle":"2026-01-21T09:57:38.961426Z","shell.execute_reply.started":"2026-01-21T09:57:38.937314Z","shell.execute_reply":"2026-01-21T09:57:38.960928Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def to_sft_text(example):\n    # skip GoEmotions (no LM supervision)\n    if all(l == -100 for l in example[\"labels\"]):\n        return {\"text\": None}\n\n    text = tokenizer.decode(\n        example[\"input_ids\"],\n        skip_special_tokens=False\n    )\n    return {\"text\": text}\n\nsft_dataset = mixed_dataset.map(to_sft_text)\nsft_dataset = sft_dataset.filter(lambda x: x[\"text\"] is not None)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T09:57:38.962136Z","iopub.execute_input":"2026-01-21T09:57:38.962321Z","iopub.status.idle":"2026-01-21T09:58:34.717363Z","shell.execute_reply.started":"2026-01-21T09:57:38.962300Z","shell.execute_reply":"2026-01-21T09:58:34.716691Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/163118 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"46f3761f0ea341deb348ed27b0f312bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/163118 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb3072cd7c80474fb523bd66fb99b118"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"from trl import SFTConfig, SFTTrainer\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = sft_dataset,\n    args = SFTConfig(\n        per_device_train_batch_size = 1,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        # num_train_epochs = 1, # Set this for 1 full training run.\n        max_steps = 30,\n        learning_rate = 2e-4,\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.0001,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"none\", # Use TrackIO/WandB etc\n    ),\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:37:24.907342Z","iopub.execute_input":"2026-01-20T14:37:24.907592Z","iopub.status.idle":"2026-01-20T14:37:25.385930Z","shell.execute_reply.started":"2026-01-20T14:37:24.907567Z","shell.execute_reply":"2026-01-20T14:37:25.385357Z"}},"outputs":[{"name":"stdout","text":"Unsloth: Switching to float32 training since model cannot work with float16\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:39:47.927240Z","iopub.execute_input":"2026-01-20T14:39:47.927704Z","iopub.status.idle":"2026-01-20T14:47:59.650388Z","shell.execute_reply.started":"2026-01-20T14:39:47.927663Z","shell.execute_reply":"2026-01-20T14:47:59.649517Z"}},"outputs":[{"name":"stderr","text":"==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n   \\\\   /|    Num examples = 109,992 | Num Epochs = 1 | Total steps = 30\nO^O/ \\_/ \\    Batch size per device = 1 | Gradient accumulation steps = 4\n\\        /    Data Parallel GPUs = 1 | Total batch size (1 x 4 x 1) = 4\n \"-____-\"     Trainable parameters = 3,981,312 of 20,918,738,496 (0.02% trained)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [30/30 07:55, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>4.141200</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>4.637700</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>4.948400</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>4.197000</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>4.157900</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>3.809800</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>3.472100</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>3.203300</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>3.744700</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>2.819100</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>2.560100</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>2.365900</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>2.524200</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>2.756900</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>2.367100</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>2.957500</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>2.514200</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>2.314800</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>2.462900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>3.119200</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>2.108600</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>2.068100</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>2.158000</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>2.397400</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>2.632400</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>2.698600</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>2.230500</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>3.018100</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>2.576100</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.393200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=30, training_loss=2.978499674797058, metrics={'train_runtime': 488.0014, 'train_samples_per_second': 0.246, 'train_steps_per_second': 0.061, 'total_flos': 3342854770163712.0, 'train_loss': 2.978499674797058, 'epoch': 0.0010909884355225835})"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"model.save_pretrained(\"finetuned_model-1\")\nmodel.push_to_hub(\"Aharneish/finetuned_model-1\", token=\"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\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-20T14:47:59.651925Z","iopub.execute_input":"2026-01-20T14:47:59.652196Z","iopub.status.idle":"2026-01-20T14:48:04.870769Z","shell.execute_reply.started":"2026-01-20T14:47:59.652167Z","shell.execute_reply":"2026-01-20T14:48:04.869941Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/567 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ea70be66af49abb54879d6364609a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"36b979f6c8c941629a8fca2186f5cc5a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15e4a5b12ada478e9928da985e106f69"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/Aharneish/finetuned_model-1\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"%%capture\nimport os, importlib.util\n!pip install --upgrade -qqq uv\nif importlib.util.find_spec(\"torch\") is None or \"COLAB_\" in \"\".join(os.environ.keys()):    \n    try: import numpy, PIL; get_numpy = f\"numpy=={numpy.__version__}\"; get_pil = f\"pillow=={PIL.__version__}\"\n    except: get_numpy = \"numpy\"; get_pil = \"pillow\"\n    !uv pip install -qqq \\\n        \"torch>=2.8.0\" \"triton>=3.4.0\" {get_numpy} {get_pil} torchvision bitsandbytes \"transformers==4.56.2\" \\\n        \"unsloth_zoo[base] @ git+https://github.com/unslothai/unsloth-zoo\" \\\n        \"unsloth[base] @ git+https://github.com/unslothai/unsloth\" \\\n        git+https://github.com/triton-lang/triton.git@0add68262ab0a2e33b84524346cb27cbb2787356#subdirectory=python/triton_kernels\nelif importlib.util.find_spec(\"unsloth\") is None:\n    !uv pip install -qqq unsloth\n!uv pip install --upgrade --no-deps transformers==4.56.2 tokenizers trl==0.22.2 unsloth unsloth_zoo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:17:56.320501Z","iopub.execute_input":"2026-01-21T14:17:56.321154Z","iopub.status.idle":"2026-01-21T14:18:20.661246Z","shell.execute_reply.started":"2026-01-21T14:17:56.321126Z","shell.execute_reply":"2026-01-21T14:18:20.660429Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n        model_name = \"Aharneish/finetuned_model-1\", # YOUR MODEL YOU USED FOR TRAINING\n        max_seq_length = 4098,\n        dtype = None,\n        load_in_4bit = True,\n    )\n\nmessages = [\n    {\"role\": \"system\", \"content\": \"You are a emotional support assistant. your job is to respond with empathy and emotions\"},\n    {\"role\": \"user\", \"content\": \"I feel depressed\"},\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:41:40.231711Z","iopub.execute_input":"2026-01-21T14:41:40.231965Z","iopub.status.idle":"2026-01-21T14:43:47.453300Z","shell.execute_reply.started":"2026-01-21T14:41:40.231938Z","shell.execute_reply":"2026-01-21T14:43:47.452342Z"}},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2026-01-21 14:41:53.196386: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1769006513.573725      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1769006513.643169      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1769006514.207502      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769006514.207539      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769006514.207542      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1769006514.207544      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"},{"name":"stdout","text":"ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2026.1.3: Fast Gpt_Oss patching. Transformers: 4.56.2.\n   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\nO^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.4.0\n\\        /    Bfloat16 = FALSE. FA [Xformers = None. FA2 = False]\n \"-____-\"     Free license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\nUnsloth: Using float16 precision for gpt_oss won't work! Using float32.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab47ab1ea1d348a2a8d14890e33e9665"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6dad3f3680ba4d9d9d55a38879807860"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00004.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"923a5f778e274954bbeb3c40afcf7c00"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00004.safetensors:   0%|          | 0.00/3.37G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3b34a2b34c147338dce64c495126e3a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00004-of-00004.safetensors:   0%|          | 0.00/1.16G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1062e01d38e943358546b6dce71813ba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73a4277a724c45cbba53ce487ae383bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/165 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a47ff90ef954fa8bbb401a618b54880"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa3d4fdf16d945a19d0f31d05ed2da4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/27.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47e378088f9741499369ec92707d0b48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/446 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9889c41fa4fd4b019e5e4dd896fc7464"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"chat_template.jinja: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfde1ac28bb14703af6dd71051862d63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"adapter_model.safetensors:   0%|          | 0.00/16.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c81a1aa813874271b0a49c005194e5a7"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"inputs = tokenizer.apply_chat_template(\n    messages,\n    add_generation_prompt = True,\n    return_tensors = \"pt\",\n    return_dict = True,\n    reasoning_effort = \"high\",\n).to(\"cuda\")\nfrom transformers import TextStreamer\n_ = model.generate(**inputs, max_new_tokens = 64, streamer = TextStreamer(tokenizer))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T10:14:14.021973Z","iopub.execute_input":"2026-01-21T10:14:14.022305Z","iopub.status.idle":"2026-01-21T10:15:22.086581Z","shell.execute_reply.started":"2026-01-21T10:14:14.022275Z","shell.execute_reply":"2026-01-21T10:15:22.085764Z"}},"outputs":[{"name":"stdout","text":"<|start|>system<|message|>You are ChatGPT, a large language model trained by OpenAI.\nKnowledge cutoff: 2024-06\nCurrent date: 2026-01-21\n\nReasoning: high\n\n# Valid channels: analysis, commentary, final. Channel must be included for every message.\nCalls to these tools must go to the commentary channel: 'functions'.<|end|><|start|>developer<|message|># Instructions\n\nYou are a emotional support assistant. your job is to respond with empathy and emotions<|end|><|start|>user<|message|>I feel depressed<|end|><|start|>assistant<|channel|>analysis<|message|>The user says \"I feel depressed\". This is a statement of emotion. According to the instruction hierarchy, \"the system message\" says \"You are ChatGPT, a large language model trained by OpenAI.\" No direct instructions from a developer are conflicting with the system message. The developer message is \"You\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nmodel.eval()\nfor param in model.parameters():\n    param.requires_grad = False\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:43:58.311777Z","iopub.execute_input":"2026-01-21T14:43:58.312642Z","iopub.status.idle":"2026-01-21T14:43:58.342933Z","shell.execute_reply.started":"2026-01-21T14:43:58.312595Z","shell.execute_reply":"2026-01-21T14:43:58.342167Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"class LogitBottleneck(nn.Module):\n    def __init__(self, vocab_size, bottleneck_dim=512):\n        super().__init__()\n        self.proj = nn.Linear(vocab_size, bottleneck_dim, bias=False)\n\n    def forward(self, x):\n        return self.proj(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:20:42.412985Z","iopub.execute_input":"2026-01-21T14:20:42.413237Z","iopub.status.idle":"2026-01-21T14:20:42.418642Z","shell.execute_reply.started":"2026-01-21T14:20:42.413211Z","shell.execute_reply":"2026-01-21T14:20:42.418143Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:22:43.751491Z","iopub.execute_input":"2026-01-21T14:22:43.752340Z","iopub.status.idle":"2026-01-21T14:22:43.756957Z","shell.execute_reply.started":"2026-01-21T14:22:43.752302Z","shell.execute_reply":"2026-01-21T14:22:43.756216Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"vocab_size = model.config.vocab_size\nbottleneck = LogitBottleneck(vocab_size, bottleneck_dim=512).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:22:44.531526Z","iopub.execute_input":"2026-01-21T14:22:44.532009Z","iopub.status.idle":"2026-01-21T14:22:45.446758Z","shell.execute_reply.started":"2026-01-21T14:22:44.531969Z","shell.execute_reply":"2026-01-21T14:22:45.445935Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"def get_pooled_features(model, input_ids, attention_mask):\n    \"\"\"Extract pooled features from the model\"\"\"\n    with torch.no_grad():\n        # For Unsloth models, we need to use the base model\n        if hasattr(model, 'model'):\n            base_model = model.model\n        else:\n            base_model = model\n            \n        outputs = base_model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            output_hidden_states=True,\n            return_dict=True\n        )\n    \n    # Get the last hidden state\n    if hasattr(outputs, 'hidden_states') and outputs.hidden_states is not None:\n        hidden_states = outputs.hidden_states[-1]\n    elif hasattr(outputs, 'last_hidden_state'):\n        hidden_states = outputs.last_hidden_state\n    else:\n        # Fallback: try to get hidden states directly\n        raise ValueError(\"Could not extract hidden states from model output\")\n    \n    # Pool by taking the last token's representation\n    sequence_lengths = attention_mask.sum(dim=1) - 1\n    batch_size = hidden_states.size(0)\n    \n    # Gather last token embeddings\n    pooled = hidden_states[torch.arange(batch_size, device=device), sequence_lengths]\n    \n    return pooled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:26:42.233905Z","iopub.execute_input":"2026-01-21T14:26:42.234254Z","iopub.status.idle":"2026-01-21T14:26:42.240772Z","shell.execute_reply.started":"2026-01-21T14:26:42.234222Z","shell.execute_reply":"2026-01-21T14:26:42.240127Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"class EmotionHead(nn.Module):\n    def __init__(self, hidden_dim, num_labels=28):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_labels)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:27:08.265803Z","iopub.execute_input":"2026-01-21T14:27:08.266159Z","iopub.status.idle":"2026-01-21T14:27:08.271971Z","shell.execute_reply.started":"2026-01-21T14:27:08.266125Z","shell.execute_reply":"2026-01-21T14:27:08.271206Z"}},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":"class EmotionHead(nn.Module):\n    def __init__(self, bottleneck_dim=512, num_labels=28):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.LayerNorm(bottleneck_dim),\n            nn.Linear(bottleneck_dim, num_labels)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:15:22.115435Z","iopub.execute_input":"2026-01-21T10:15:22.115701Z","iopub.status.idle":"2026-01-21T10:15:22.126108Z","shell.execute_reply.started":"2026-01-21T10:15:22.115674Z","shell.execute_reply":"2026-01-21T10:15:22.125495Z"}}},{"cell_type":"markdown","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nvocab_size = model.config.vocab_size\nemotion_head = EmotionHead(vocab_size).to(device)\n\noptimizer = torch.optim.AdamW(\n    emotion_head.parameters(),\n    lr=2e-4\n)\n\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:16:23.213475Z","iopub.execute_input":"2026-01-21T10:16:23.213869Z","iopub.status.idle":"2026-01-21T10:16:23.278242Z","shell.execute_reply.started":"2026-01-21T10:16:23.213832Z","shell.execute_reply":"2026-01-21T10:16:23.277502Z"}}},{"cell_type":"markdown","source":"from torch.utils.data import DataLoader\n\ndef collate_fn(batch):\n    input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n    labels = torch.tensor([x[\"emotion_label\"] for x in batch])\n\n    input_ids = nn.utils.rnn.pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.pad_token_id\n    )\n\n    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"attention_mask\": attention_mask.to(device),\n        \"labels\": labels.to(device)\n    }\n\nemotion_loader = DataLoader(\n    dataset3,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn\n)\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T14:24:05.672138Z","iopub.execute_input":"2026-01-21T14:24:05.672964Z","iopub.status.idle":"2026-01-21T14:24:05.680313Z","shell.execute_reply.started":"2026-01-21T14:24:05.672894Z","shell.execute_reply":"2026-01-21T14:24:05.679420Z"}}},{"cell_type":"code","source":"def collate_fn(batch):\n    input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n    labels = torch.tensor([x[\"emotion_label\"] for x in batch])\n\n    input_ids = nn.utils.rnn.pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.pad_token_id\n    )\n\n    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"attention_mask\": attention_mask.to(device),\n        \"labels\": labels.to(device)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:27:18.585841Z","iopub.execute_input":"2026-01-21T14:27:18.586391Z","iopub.status.idle":"2026-01-21T14:27:18.591258Z","shell.execute_reply.started":"2026-01-21T14:27:18.586345Z","shell.execute_reply":"2026-01-21T14:27:18.590487Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"emotion_loader = DataLoader(\n    dataset3,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:28:04.649007Z","iopub.execute_input":"2026-01-21T14:28:04.649808Z","iopub.status.idle":"2026-01-21T14:28:04.654037Z","shell.execute_reply.started":"2026-01-21T14:28:04.649772Z","shell.execute_reply":"2026-01-21T14:28:04.653253Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"def get_pooled_features(model, input_ids, attention_mask, bottleneck):\n    with torch.no_grad():\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True,\n            logits_to_keep=1   # ðŸš¨ CRITICAL (last token only)\n        )\n\n    # logits: (B, 1, vocab)\n    last_logits = outputs.logits[:, 0, :]  # (B, vocab)\n\n    # project immediately to small dim\n    features = bottleneck(last_logits.float())  # (B, 512)\n\n    return features","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:13:51.907876Z","iopub.status.idle":"2026-01-21T10:13:51.908396Z","shell.execute_reply.started":"2026-01-21T10:13:51.908193Z","shell.execute_reply":"2026-01-21T10:13:51.908224Z"}}},{"cell_type":"code","source":"print(\"Model structure:\")\nif hasattr(model, 'model'):\n    print(\"  - Using model.model (PEFT wrapped)\")\n    base_model = model.model\nelse:\n    print(\"  - Using model directly\")\n    base_model = model\n\nif hasattr(model.config, 'hidden_size'):\n    hidden_dim = model.config.hidden_size\nelif hasattr(base_model.config, 'hidden_size'):\n    hidden_dim = base_model.config.hidden_size\nelse:\n    # Default for GPT-style models\n    hidden_dim = 4096\n    \nprint(f\"Hidden dimension: {hidden_dim}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:28:16.342150Z","iopub.execute_input":"2026-01-21T14:28:16.342761Z","iopub.status.idle":"2026-01-21T14:28:16.348361Z","shell.execute_reply.started":"2026-01-21T14:28:16.342724Z","shell.execute_reply":"2026-01-21T14:28:16.347535Z"}},"outputs":[{"name":"stdout","text":"Model structure:\n  - Using model.model (PEFT wrapped)\nHidden dimension: 2880\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"emotion_head = EmotionHead(hidden_dim, num_labels=28).to(device)\n\noptimizer = torch.optim.AdamW(\n    emotion_head.parameters(),\n    lr=2e-4,\n    weight_decay=0.01\n)\n\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:28:28.833075Z","iopub.execute_input":"2026-01-21T14:28:28.833746Z","iopub.status.idle":"2026-01-21T14:28:28.852805Z","shell.execute_reply.started":"2026-01-21T14:28:28.833697Z","shell.execute_reply":"2026-01-21T14:28:28.852018Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"# 7. Test feature extraction with debugging\nprint(\"\\nTesting feature extraction...\")\nbatch = next(iter(emotion_loader))\nprint(f\"Batch input_ids shape: {batch['input_ids'].shape}\")\nprint(f\"Batch labels shape: {batch['labels'].shape}\")\n\ntry:\n    features = get_pooled_features(\n        model,\n        batch[\"input_ids\"],\n        batch[\"attention_mask\"]\n    )\n    print(f\"âœ“ Extracted features shape: {features.shape}\")\n    \n    logits = emotion_head(features)\n    print(f\"âœ“ Emotion head output shape: {logits.shape}\")\n    print(\"\\nâœ“ Everything working correctly!\\n\")\n    \nexcept Exception as e:\n    print(f\"\\nâŒ Error during feature extraction: {e}\")\n    print(\"\\nTrying alternative approach...\")\n    \n    # Alternative: Use embeddings + mean pooling\n    def get_pooled_features_alternative(model, input_ids, attention_mask):\n        with torch.no_grad():\n            if hasattr(model, 'model'):\n                # Get embeddings from the base model\n                embeddings = model.model.embed_tokens(input_ids)\n            else:\n                embeddings = model.embed_tokens(input_ids)\n            \n            # Mean pooling over sequence length\n            mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n            sum_embeddings = torch.sum(embeddings * mask_expanded, 1)\n            sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n            pooled = sum_embeddings / sum_mask\n            \n        return pooled\n    \n    # Test alternative\n    features = get_pooled_features_alternative(\n        model,\n        batch[\"input_ids\"],\n        batch[\"attention_mask\"]\n    )\n    print(f\"âœ“ Alternative method - features shape: {features.shape}\")\n    \n    # Update the function globally\n    get_pooled_features = get_pooled_features_alternative\n    print(\"Using alternative pooling method\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:28:43.990629Z","iopub.execute_input":"2026-01-21T14:28:43.991392Z","iopub.status.idle":"2026-01-21T14:28:48.373294Z","shell.execute_reply.started":"2026-01-21T14:28:43.991358Z","shell.execute_reply":"2026-01-21T14:28:48.372147Z"}},"outputs":[{"name":"stdout","text":"\nTesting feature extraction...\nBatch input_ids shape: torch.Size([16, 29])\nBatch labels shape: torch.Size([16])\n\nâŒ Error during feature extraction: Could not extract hidden states from model output\n\nTrying alternative approach...\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1722471466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     features = get_pooled_features(\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1024383469.py\u001b[0m in \u001b[0;36mget_pooled_features\u001b[0;34m(model, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Fallback: try to get hidden states directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Could not extract hidden states from model output\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Could not extract hidden states from model output","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/1722471466.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Test alternative\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     features = get_pooled_features_alternative(\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_55/1722471466.py\u001b[0m in \u001b[0;36mget_pooled_features_alternative\u001b[0;34m(model, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0;31m# Get embeddings from the base model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1960\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1963\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m         )\n","\u001b[0;31mAttributeError\u001b[0m: 'GptOssForCausalLM' object has no attribute 'embed_tokens'"],"ename":"AttributeError","evalue":"'GptOssForCausalLM' object has no attribute 'embed_tokens'","output_type":"error"}],"execution_count":37},{"cell_type":"markdown","source":"batch = next(iter(emotion_loader))\npooled = get_pooled_features(\n    model,\n    batch[\"input_ids\"],\n    batch[\"attention_mask\"],\n    bottleneck\n).float()\n\nprint(pooled.shape)\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T14:24:08.576113Z","iopub.execute_input":"2026-01-21T14:24:08.576740Z","iopub.status.idle":"2026-01-21T14:24:08.589383Z","shell.execute_reply.started":"2026-01-21T14:24:08.576704Z","shell.execute_reply":"2026-01-21T14:24:08.588444Z"}}},{"cell_type":"markdown","source":"num_epochs = 3\nlog_every = 100\nstep = 0\n\nemotion_head.train()\n\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n\n    for batch in emotion_loader:\n        features = get_pooled_features(\n            model,\n            batch[\"input_ids\"],\n            batch[\"attention_mask\"],\n            bottleneck\n        )\n        \n        logits = emotion_head(features)\n        loss = criterion(logits, batch[\"labels\"])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        step += 1\n\n        if step % log_every == 0:\n            print(f\"Epoch {epoch} | Step {step} | Loss {loss.item():.4f}\")\n\n    avg = total_loss / len(emotion_loader)\n    print(f\"Epoch {epoch} finished | Avg loss {avg:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:13:51.911701Z","iopub.status.idle":"2026-01-21T10:13:51.912019Z","shell.execute_reply.started":"2026-01-21T10:13:51.911846Z","shell.execute_reply":"2026-01-21T10:13:51.911864Z"}}},{"cell_type":"code","source":"num_epochs = 3\nlog_every = 100\nstep = 0\n\nemotion_head.train()\n\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n    num_batches = 0\n\n    for batch in emotion_loader:\n        # Extract features from the model\n        features = get_pooled_features(\n            model,\n            batch[\"input_ids\"],\n            batch[\"attention_mask\"]\n        )\n        \n        # Forward pass through emotion head\n        logits = emotion_head(features)\n        loss = criterion(logits, batch[\"labels\"])\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        num_batches += 1\n        step += 1\n\n        if step % log_every == 0:\n            print(f\"Epoch {epoch} | Step {step} | Loss {loss.item():.4f}\")\n\n    avg_loss = total_loss / num_batches\n    print(f\"Epoch {epoch} finished | Avg loss {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:25:49.453269Z","iopub.status.idle":"2026-01-21T14:25:49.453664Z","shell.execute_reply.started":"2026-01-21T14:25:49.453493Z","shell.execute_reply":"2026-01-21T14:25:49.453517Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"def evaluate_emotion_head(model, head, dataloader):\n    head.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            pooled = get_pooled_hidden_states(\n                model,\n                batch[\"input_ids\"],\n                batch[\"attention_mask\"]\n            )\n            logits = head(pooled)\n            preds = logits.argmax(dim=-1)\n\n            correct += (preds == batch[\"labels\"]).sum().item()\n            total += batch[\"labels\"].size(0)\n\n    acc = correct / total\n    print(f\"Emotion accuracy: {acc:.4f}\")\n    head.train()\n\nevaluate_emotion_head(model, emotion_head, emotion_loader)\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:05:25.403924Z","iopub.execute_input":"2026-01-21T10:05:25.404531Z","iopub.status.idle":"2026-01-21T10:05:25.417441Z","shell.execute_reply.started":"2026-01-21T10:05:25.404499Z","shell.execute_reply":"2026-01-21T10:05:25.416477Z"}}},{"cell_type":"code","source":"def evaluate_emotion_head(model, head, dataloader):\n    head.eval()\n    correct, total = 0, 0\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for batch in dataloader:\n            features = get_pooled_features(\n                model,\n                batch[\"input_ids\"],\n                batch[\"attention_mask\"]\n            )\n            logits = head(features)\n            preds = logits.argmax(dim=-1)\n\n            correct += (preds == batch[\"labels\"]).sum().item()\n            total += batch[\"labels\"].size(0)\n            \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(batch[\"labels\"].cpu().numpy())\n\n    acc = correct / total\n    print(f\"Emotion classification accuracy: {acc:.4f}\")\n    head.train()\n    \n    return acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"evaluate_emotion_head(model, emotion_head, emotion_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"torch.save(\n    emotion_head.state_dict(),\n    \"emotion_head.pt\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2026-01-21T10:05:26.676624Z","iopub.execute_input":"2026-01-21T10:05:26.676990Z","iopub.status.idle":"2026-01-21T10:05:26.713242Z","shell.execute_reply.started":"2026-01-21T10:05:26.676957Z","shell.execute_reply":"2026-01-21T10:05:26.712489Z"}}},{"cell_type":"code","source":"torch.save({\n    'emotion_head_state_dict': emotion_head.state_dict(),\n    'hidden_dim': hidden_dim,\n}, \"emotion_head.pt\")\n\nprint(\"Emotion head saved successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ===== PROBE MODEL STRUCTURE FIRST =====\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nprint(\"=\"*60)\nprint(\"DEBUGGING MODEL STRUCTURE\")\nprint(\"=\"*60)\n\n# Check model type and attributes\nprint(f\"\\nModel type: {type(model)}\")\nprint(f\"Model class name: {model.__class__.__name__}\")\n\n# Check if it's a PEFT model\nif hasattr(model, 'model'):\n    print(f\"Base model type: {type(model.model)}\")\n    print(f\"Base model class: {model.model.__class__.__name__}\")\n    base = model.model\nelse:\n    base = model\n\n# List all attributes\nprint(\"\\nModel attributes:\")\nfor attr in dir(base):\n    if not attr.startswith('_'):\n        print(f\"  - {attr}\")\n\n# Check config\nprint(f\"\\nConfig hidden_size: {model.config.hidden_size}\")\nprint(f\"Config vocab_size: {model.config.vocab_size}\")\n\n# Try to find embedding layer\nprint(\"\\nSearching for embedding layer...\")\nif hasattr(base, 'transformer'):\n    print(\"  âœ“ Found: model.transformer\")\n    if hasattr(base.transformer, 'wte'):\n        print(\"  âœ“ Found: model.transformer.wte (word token embeddings)\")\n    if hasattr(base.transformer, 'embed_tokens'):\n        print(\"  âœ“ Found: model.transformer.embed_tokens\")\n        \nif hasattr(base, 'model'):\n    print(\"  âœ“ Found: model.model\")\n    if hasattr(base.model, 'embed_tokens'):\n        print(\"  âœ“ Found: model.model.embed_tokens\")\n    if hasattr(base.model, 'decoder'):\n        print(\"  âœ“ Found: model.model.decoder\")\n        if hasattr(base.model.decoder, 'embed_tokens'):\n            print(\"  âœ“ Found: model.model.decoder.embed_tokens\")\n\n# Check what the model returns\nprint(\"\\nTesting model output...\")\ntest_input = torch.randint(0, 100, (2, 10)).to(device)\ntest_mask = torch.ones(2, 10).to(device)\n\nwith torch.no_grad():\n    try:\n        out = base(test_input, attention_mask=test_mask, output_hidden_states=True, return_dict=True)\n        print(f\"  Output type: {type(out)}\")\n        print(f\"  Output keys: {out.keys() if hasattr(out, 'keys') else 'N/A'}\")\n        if hasattr(out, 'hidden_states'):\n            print(f\"  hidden_states: {out.hidden_states is not None}\")\n            if out.hidden_states:\n                print(f\"  Number of hidden layers: {len(out.hidden_states)}\")\n                print(f\"  Last hidden state shape: {out.hidden_states[-1].shape}\")\n        if hasattr(out, 'last_hidden_state'):\n            print(f\"  last_hidden_state shape: {out.last_hidden_state.shape}\")\n    except Exception as e:\n        print(f\"  Error: {e}\")\n\nprint(\"\\n\" + \"=\"*60)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:34.143858Z","iopub.execute_input":"2026-01-21T14:45:34.144432Z","iopub.status.idle":"2026-01-21T14:45:46.725893Z","shell.execute_reply.started":"2026-01-21T14:45:34.144390Z","shell.execute_reply":"2026-01-21T14:45:46.725100Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"============================================================\nDEBUGGING MODEL STRUCTURE\n============================================================\n\nModel type: <class 'peft.peft_model.PeftModelForCausalLM'>\nModel class name: PeftModelForCausalLM\nBase model type: <class 'transformers.models.gpt_oss.modeling_gpt_oss.GptOssForCausalLM'>\nBase model class: GptOssForCausalLM\n\nModel attributes:\n  - T_destination\n  - active_adapter\n  - active_adapters\n  - add_adapter\n  - add_memory_hooks\n  - add_model_tags\n  - add_module\n  - apply\n  - base_model\n  - base_model_prefix\n  - bfloat16\n  - buffers\n  - call_super_init\n  - can_generate\n  - can_record_outputs\n  - children\n  - compile\n  - compute_transition_scores\n  - config\n  - config_class\n  - cpu\n  - create_extended_attention_mask_for_decoder\n  - cuda\n  - delete_adapter\n  - dequantize\n  - device\n  - disable_adapters\n  - disable_input_require_grads\n  - double\n  - dtype\n  - dummy_inputs\n  - dump_patches\n  - enable_adapters\n  - enable_input_require_grads\n  - estimate_tokens\n  - eval\n  - extra_repr\n  - fast_generate\n  - fast_generate_batches\n  - float\n  - floating_point_ops\n  - for_inference\n  - for_training\n  - forward\n  - framework\n  - from_pretrained\n  - generate\n  - generate\n  - generate_batch\n  - generation_config\n  - get_adapter_state_dict\n  - get_buffer\n  - get_compiled_call\n  - get_correct_attn_implementation\n  - get_decoder\n  - get_extended_attention_mask\n  - get_extra_state\n  - get_head_mask\n  - get_init_context\n  - get_input_embeddings\n  - get_memory_footprint\n  - get_output_embeddings\n  - get_parameter\n  - get_parameter_or_buffer\n  - get_position_embeddings\n  - get_submodule\n  - gradient_checkpointing_disable\n  - gradient_checkpointing_enable\n  - half\n  - heal_tokens\n  - hf_device_map\n  - hf_quantizer\n  - init_continuous_batching\n  - init_weights\n  - initialize_weights\n  - invert_attention_mask\n  - ipu\n  - is_4bit_serializable\n  - is_backend_compatible\n  - is_gradient_checkpointing\n  - is_loaded_in_4bit\n  - is_loaded_in_8bit\n  - is_parallelizable\n  - is_quantized\n  - lm_head\n  - load_adapter\n  - load_custom_generate\n  - load_state_dict\n  - loss_function\n  - loss_type\n  - main_input_name\n  - max_seq_length\n  - model\n  - model_tags\n  - model_tags\n  - modules\n  - mtia\n  - name_or_path\n  - named_buffers\n  - named_children\n  - named_modules\n  - named_parameters\n  - num_experts\n  - num_experts_per_tok\n  - num_parameters\n  - original_push_to_hub\n  - parameters\n  - peft_config\n  - post_init\n  - pp_plan\n  - prepare_inputs_for_generation\n  - prune_heads\n  - push_to_hub\n  - push_to_hub\n  - push_to_hub_gguf\n  - push_to_hub_merged\n  - quantization_method\n  - register_backward_hook\n  - register_buffer\n  - register_for_auto_class\n  - register_forward_hook\n  - register_forward_pre_hook\n  - register_full_backward_hook\n  - register_full_backward_pre_hook\n  - register_load_state_dict_post_hook\n  - register_load_state_dict_pre_hook\n  - register_module\n  - register_parameter\n  - register_state_dict_post_hook\n  - register_state_dict_pre_hook\n  - requires_grad_\n  - reset_memory_hooks_state\n  - resize_position_embeddings\n  - resize_token_embeddings\n  - retrieve_modules_from_names\n  - reverse_bettertransformer\n  - router_aux_loss_coef\n  - save_pretrained\n  - save_pretrained_gguf\n  - save_pretrained_merged\n  - save_pretrained_torchao\n  - set_adapter\n  - set_attn_implementation\n  - set_decoder\n  - set_extra_state\n  - set_input_embeddings\n  - set_output_embeddings\n  - set_submodule\n  - share_memory\n  - smart_apply\n  - state_dict\n  - supports_gradient_checkpointing\n  - supports_pp_plan\n  - supports_tp_plan\n  - tie_embeddings_and_encoder_decoder\n  - tie_weights\n  - to\n  - to_bettertransformer\n  - to_empty\n  - tp_plan\n  - tp_size\n  - train\n  - training\n  - type\n  - vocab_size\n  - warn_if_padding_and_no_attention_mask\n  - warnings_issued\n  - xpu\n  - zero_grad\n\nConfig hidden_size: 2880\nConfig vocab_size: 201088\n\nSearching for embedding layer...\n  âœ“ Found: model.model\n  âœ“ Found: model.model.embed_tokens\n\nTesting model output...\n  Output type: <class 'transformers.modeling_outputs.MoeCausalLMOutputWithPast'>\n  Output keys: odict_keys(['logits'])\n  hidden_states: False\n\n============================================================\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# ===== NOW CREATE THE WORKING SOLUTION =====\n\ndef get_pooled_features(model, input_ids, attention_mask):\n    \"\"\"Extract features using the actual model structure\"\"\"\n    with torch.no_grad():\n        # Access the base model\n        if hasattr(model, 'model'):\n            base = model.model\n        else:\n            base = model\n        \n        # Try different ways to get embeddings\n        embedding_layer = None\n        \n        # Method 1: Check for transformer.wte (GPT-2 style)\n        if hasattr(base, 'transformer') and hasattr(base.transformer, 'wte'):\n            embedding_layer = base.transformer.wte\n            # print(\"Using: model.transformer.wte\")\n        # Method 2: Check for model.embed_tokens (LLaMA style)\n        elif hasattr(base, 'model') and hasattr(base.model, 'embed_tokens'):\n            embedding_layer = base.model.embed_tokens\n            # print(\"Using: model.model.embed_tokens\")\n        # Method 3: Direct embed_tokens\n        elif hasattr(base, 'embed_tokens'):\n            embedding_layer = base.embed_tokens\n            # print(\"Using: model.embed_tokens\")\n        # Method 4: Check decoder\n        elif hasattr(base, 'model') and hasattr(base.model, 'decoder') and hasattr(base.model.decoder, 'embed_tokens'):\n            embedding_layer = base.model.decoder.embed_tokens\n            # print(\"Using: model.model.decoder.embed_tokens\")\n        else:\n            raise ValueError(\"Cannot find embedding layer in model\")\n        \n        # Get embeddings\n        embeddings = embedding_layer(input_ids)\n        \n        # Mean pooling with attention mask\n        mask_expanded = attention_mask.unsqueeze(-1).expand(embeddings.size()).float()\n        sum_embeddings = torch.sum(embeddings * mask_expanded, 1)\n        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n        pooled = sum_embeddings / sum_mask\n        \n    return pooled","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:46.727288Z","iopub.execute_input":"2026-01-21T14:45:46.727753Z","iopub.status.idle":"2026-01-21T14:45:46.735205Z","shell.execute_reply.started":"2026-01-21T14:45:46.727718Z","shell.execute_reply":"2026-01-21T14:45:46.734327Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# 2. EmotionHead\nclass EmotionHead(nn.Module):\n    def __init__(self, hidden_dim, num_labels=28):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_labels)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:50.416088Z","iopub.execute_input":"2026-01-21T14:45:50.416874Z","iopub.status.idle":"2026-01-21T14:45:50.421399Z","shell.execute_reply.started":"2026-01-21T14:45:50.416839Z","shell.execute_reply":"2026-01-21T14:45:50.420663Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# 3. Collate function\ndef collate_fn(batch):\n    input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n    labels = torch.tensor([x[\"emotion_label\"] for x in batch])\n\n    input_ids = nn.utils.rnn.pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.pad_token_id\n    )\n\n    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"attention_mask\": attention_mask.to(device),\n        \"labels\": labels.to(device)\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:51.584132Z","iopub.execute_input":"2026-01-21T14:45:51.584724Z","iopub.status.idle":"2026-01-21T14:45:51.589560Z","shell.execute_reply.started":"2026-01-21T14:45:51.584692Z","shell.execute_reply":"2026-01-21T14:45:51.588748Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# 4. Create DataLoader\nemotion_loader = DataLoader(\n    dataset3,\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:52.698104Z","iopub.execute_input":"2026-01-21T14:45:52.698460Z","iopub.status.idle":"2026-01-21T14:45:52.703785Z","shell.execute_reply.started":"2026-01-21T14:45:52.698425Z","shell.execute_reply":"2026-01-21T14:45:52.703020Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# 5. Get hidden dimension\nhidden_dim = model.config.hidden_size\nprint(f\"\\nHidden dimension: {hidden_dim}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:53.561840Z","iopub.execute_input":"2026-01-21T14:45:53.562150Z","iopub.status.idle":"2026-01-21T14:45:53.566201Z","shell.execute_reply.started":"2026-01-21T14:45:53.562120Z","shell.execute_reply":"2026-01-21T14:45:53.565418Z"}},"outputs":[{"name":"stdout","text":"\nHidden dimension: 2880\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# 6. Initialize\nemotion_head = EmotionHead(hidden_dim, num_labels=28).to(device)\noptimizer = torch.optim.AdamW(emotion_head.parameters(), lr=2e-4, weight_decay=0.01)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:54.690161Z","iopub.execute_input":"2026-01-21T14:45:54.690882Z","iopub.status.idle":"2026-01-21T14:45:54.707580Z","shell.execute_reply.started":"2026-01-21T14:45:54.690834Z","shell.execute_reply":"2026-01-21T14:45:54.706752Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# 7. Test\nprint(\"\\n\" + \"=\"*60)\nprint(\"TESTING FEATURE EXTRACTION\")\nprint(\"=\"*60)\n\nbatch = next(iter(emotion_loader))\nprint(f\"\\nBatch input_ids shape: {batch['input_ids'].shape}\")\nprint(f\"Batch labels shape: {batch['labels'].shape}\")\n\nfeatures = get_pooled_features(\n    model,\n    batch[\"input_ids\"],\n    batch[\"attention_mask\"]\n)\nprint(f\"\\nâœ“ Extracted features shape: {features.shape}\")\n\nlogits = emotion_head(features)\nprint(f\"âœ“ Emotion head output shape: {logits.shape}\")\nprint(\"\\nâœ“ Everything working!\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:45:55.795171Z","iopub.execute_input":"2026-01-21T14:45:55.795510Z","iopub.status.idle":"2026-01-21T14:45:56.290491Z","shell.execute_reply.started":"2026-01-21T14:45:55.795480Z","shell.execute_reply":"2026-01-21T14:45:56.289785Z"}},"outputs":[{"name":"stdout","text":"\n============================================================\nTESTING FEATURE EXTRACTION\n============================================================\n\nBatch input_ids shape: torch.Size([16, 31])\nBatch labels shape: torch.Size([16])\n\nâœ“ Extracted features shape: torch.Size([16, 2880])\nâœ“ Emotion head output shape: torch.Size([16, 28])\n\nâœ“ Everything working!\n\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# 8. Training loop with nested tqdm (epochs + batches)\nfrom tqdm import tqdm\n\nnum_epochs = 10\nlog_every = 100\nstep = 0\n\nprint(\"=\"*60)\nprint(\"STARTING TRAINING\")\nprint(\"=\"*60 + \"\\n\")\n\nemotion_head.train()\n\n# Outer progress bar for epochs\nepoch_pbar = tqdm(range(num_epochs), desc=\"Training Progress\", \n                  unit=\"epoch\", position=0)\n\nfor epoch in epoch_pbar:\n    total_loss = 0.0\n    num_batches = 0\n    \n    # Inner progress bar for batches\n    batch_pbar = tqdm(emotion_loader, \n                      desc=f\"Epoch {epoch+1}/{num_epochs}\", \n                      unit=\"batch\", \n                      position=1, \n                      leave=False)\n    \n    for batch_idx, batch in enumerate(batch_pbar):\n        features = get_pooled_features(\n            model,\n            batch[\"input_ids\"],\n            batch[\"attention_mask\"]\n        )\n        \n        logits = emotion_head(features)\n        loss = criterion(logits, batch[\"labels\"])\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n        num_batches += 1\n        step += 1\n        \n        # Update batch progress bar\n        # batch_pbar.set_postfix({\n        #     'loss': f'{loss.item():.4f}',\n        #     'avg': f'{total_loss/num_batches:.4f}'\n        # })\n        \n        if step % log_every == 0:\n            tqdm.write(f\"[Step {step}] Loss: {loss.item():.4f}\")\n    \n    avg_loss = total_loss / num_batches\n    \n    # Update epoch progress bar with summary\n    epoch_pbar.set_postfix({\n        'avg_loss': f'{avg_loss:.4f}'\n    })\n    \n    # Print epoch summary\n    tqdm.write(f\"Epoch {epoch+1}/{num_epochs} completed | Avg Loss: {avg_loss:.4f}\")\n\nprint(\"\\nâœ“ Training completed!\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:48:28.697734Z","iopub.execute_input":"2026-01-21T14:48:28.698269Z","iopub.status.idle":"2026-01-21T14:50:03.842266Z","shell.execute_reply.started":"2026-01-21T14:48:28.698238Z","shell.execute_reply":"2026-01-21T14:50:03.841413Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"============================================================\nSTARTING TRAINING\n============================================================\n\n","output_type":"stream"},{"name":"stderr","text":"Training Progress:   0%|          | 0/10 [00:00<?, ?epoch/s]\nEpoch 1/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 1/10:   1%|          | 29/2714 [00:00<00:09, 280.89batch/s]\u001b[A\nEpoch 1/10:   2%|â–         | 58/2714 [00:00<00:09, 281.41batch/s]\u001b[A\nEpoch 1/10:   3%|â–Ž         | 87/2714 [00:00<00:09, 283.29batch/s]\u001b[A\n                                                                 \nTraining Progress:   0%|          | 0/10 [00:00<?, ?epoch/s]ch/s]\u001b[A\nEpoch 1/10:   4%|â–         | 116/2714 [00:00<00:09, 278.37batch/s]\u001b[A\nEpoch 1/10:   5%|â–Œ         | 144/2714 [00:00<00:09, 276.92batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 100] Loss: 1.4624\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:   6%|â–‹         | 172/2714 [00:00<00:09, 268.19batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:00<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:   7%|â–‹         | 200/2714 [00:00<00:09, 270.10batch/s]\u001b[A\nEpoch 1/10:   8%|â–Š         | 230/2714 [00:00<00:08, 277.99batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 200] Loss: 1.6538\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  10%|â–‰         | 258/2714 [00:00<00:08, 277.63batch/s]\u001b[A\nEpoch 1/10:  11%|â–ˆ         | 288/2714 [00:01<00:08, 282.54batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:01<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  12%|â–ˆâ–        | 317/2714 [00:01<00:08, 278.39batch/s]\u001b[A\nEpoch 1/10:  13%|â–ˆâ–Ž        | 347/2714 [00:01<00:08, 283.71batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 300] Loss: 1.2863\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  14%|â–ˆâ–        | 377/2714 [00:01<00:08, 286.04batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:01<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  15%|â–ˆâ–        | 406/2714 [00:01<00:08, 283.97batch/s]\u001b[A\nEpoch 1/10:  16%|â–ˆâ–Œ        | 436/2714 [00:01<00:07, 288.04batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 400] Loss: 1.3529\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  17%|â–ˆâ–‹        | 466/2714 [00:01<00:07, 290.72batch/s]\u001b[A\nEpoch 1/10:  18%|â–ˆâ–Š        | 496/2714 [00:01<00:07, 290.33batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:01<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  19%|â–ˆâ–‰        | 526/2714 [00:01<00:07, 285.33batch/s]\u001b[A\nEpoch 1/10:  20%|â–ˆâ–ˆ        | 556/2714 [00:01<00:07, 288.37batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 500] Loss: 1.1732\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  22%|â–ˆâ–ˆâ–       | 586/2714 [00:02<00:07, 290.63batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:02<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  23%|â–ˆâ–ˆâ–Ž       | 616/2714 [00:02<00:07, 286.33batch/s]\u001b[A\nEpoch 1/10:  24%|â–ˆâ–ˆâ–       | 646/2714 [00:02<00:07, 288.87batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 600] Loss: 2.0461\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  25%|â–ˆâ–ˆâ–       | 676/2714 [00:02<00:07, 290.72batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:02<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  26%|â–ˆâ–ˆâ–Œ       | 706/2714 [00:02<00:06, 287.52batch/s]\u001b[A\nEpoch 1/10:  27%|â–ˆâ–ˆâ–‹       | 736/2714 [00:02<00:06, 290.29batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 700] Loss: 1.7091\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  28%|â–ˆâ–ˆâ–Š       | 766/2714 [00:02<00:06, 290.70batch/s]\u001b[A\nEpoch 1/10:  29%|â–ˆâ–ˆâ–‰       | 796/2714 [00:02<00:06, 291.07batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:02<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  30%|â–ˆâ–ˆâ–ˆ       | 826/2714 [00:02<00:06, 285.46batch/s]\u001b[A\nEpoch 1/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 856/2714 [00:03<00:06, 287.33batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 800] Loss: 1.4791\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 886/2714 [00:03<00:06, 288.41batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:03<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 915/2714 [00:03<00:06, 284.33batch/s]\u001b[A\nEpoch 1/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 945/2714 [00:03<00:06, 287.84batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 900] Loss: 1.4820\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 975/2714 [00:03<00:05, 289.97batch/s]\u001b[A\n                                                                  \nTraining Progress:   0%|          | 0/10 [00:03<?, ?epoch/s]tch/s]\u001b[A\nEpoch 1/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1005/2714 [00:03<00:05, 285.78batch/s]\u001b[A\nEpoch 1/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1035/2714 [00:03<00:05, 289.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1000] Loss: 0.9809\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1064/2714 [00:03<00:05, 289.31batch/s]\u001b[A\nEpoch 1/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1094/2714 [00:03<00:05, 291.52batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:03<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1124/2714 [00:03<00:05, 286.62batch/s]\u001b[A\nEpoch 1/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1154/2714 [00:04<00:05, 288.17batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1100] Loss: 1.4755\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1184/2714 [00:04<00:05, 289.13batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:04<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1213/2714 [00:04<00:05, 285.16batch/s]\u001b[A\nEpoch 1/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1243/2714 [00:04<00:05, 287.78batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1200] Loss: 1.1038\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1273/2714 [00:04<00:04, 289.56batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:04<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1302/2714 [00:04<00:04, 285.71batch/s]\u001b[A\nEpoch 1/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1332/2714 [00:04<00:04, 288.18batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1300] Loss: 1.0248\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1361/2714 [00:04<00:04, 288.59batch/s]\u001b[A\nEpoch 1/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1391/2714 [00:04<00:04, 291.05batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:04<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1421/2714 [00:04<00:04, 284.55batch/s]\u001b[A\nEpoch 1/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1451/2714 [00:05<00:04, 286.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1400] Loss: 1.2450\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1480/2714 [00:05<00:04, 286.74batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:05<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1509/2714 [00:05<00:04, 281.90batch/s]\u001b[A\nEpoch 1/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1539/2714 [00:05<00:04, 284.62batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1500] Loss: 1.4555\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1568/2714 [00:05<00:04, 285.64batch/s]\u001b[A\nEpoch 1/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1598/2714 [00:05<00:03, 287.76batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:05<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1627/2714 [00:05<00:03, 283.88batch/s]\u001b[A\nEpoch 1/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1656/2714 [00:05<00:03, 285.48batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1600] Loss: 1.4119\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1686/2714 [00:05<00:03, 286.90batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:05<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1715/2714 [00:06<00:03, 282.36batch/s]\u001b[A\nEpoch 1/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1745/2714 [00:06<00:03, 286.97batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1700] Loss: 1.3362\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1774/2714 [00:06<00:03, 285.45batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:06<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1803/2714 [00:06<00:03, 279.67batch/s]\u001b[A\nEpoch 1/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1832/2714 [00:06<00:03, 282.41batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1800] Loss: 1.5632\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1862/2714 [00:06<00:02, 285.38batch/s]\u001b[A\nEpoch 1/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1892/2714 [00:06<00:02, 287.55batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:06<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1921/2714 [00:06<00:02, 283.56batch/s]\u001b[A\nEpoch 1/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1951/2714 [00:06<00:02, 286.49batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 1900] Loss: 1.5469\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1981/2714 [00:06<00:02, 288.78batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:07<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2010/2714 [00:07<00:02, 283.55batch/s]\u001b[A\nEpoch 1/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2040/2714 [00:07<00:02, 287.64batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2000] Loss: 1.1513\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2070/2714 [00:07<00:02, 290.07batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:07<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2100/2714 [00:07<00:02, 286.60batch/s]\u001b[A\nEpoch 1/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2130/2714 [00:07<00:02, 289.05batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2100] Loss: 1.3417\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2160/2714 [00:07<00:01, 290.53batch/s]\u001b[A\nEpoch 1/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2190/2714 [00:07<00:01, 292.34batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:07<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2220/2714 [00:07<00:01, 286.33batch/s]\u001b[A\nEpoch 1/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2250/2714 [00:07<00:01, 288.82batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2200] Loss: 1.3947\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2280/2714 [00:07<00:01, 290.61batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:08<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2310/2714 [00:08<00:01, 286.22batch/s]\u001b[A\nEpoch 1/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2340/2714 [00:08<00:01, 290.09batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2300] Loss: 0.9146\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2370/2714 [00:08<00:01, 291.04batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:08<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2400/2714 [00:08<00:01, 286.89batch/s]\u001b[A\nEpoch 1/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2430/2714 [00:08<00:00, 288.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2400] Loss: 1.6562\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2460/2714 [00:08<00:00, 289.68batch/s]\u001b[A\nEpoch 1/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2491/2714 [00:08<00:00, 292.90batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:08<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2521/2714 [00:08<00:00, 281.40batch/s]\u001b[A\nEpoch 1/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2550/2714 [00:08<00:00, 283.30batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2500] Loss: 1.4956\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2580/2714 [00:09<00:00, 286.04batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:09<?, ?epoch/s]atch/s]\u001b[A\nEpoch 1/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2609/2714 [00:09<00:00, 281.19batch/s]\u001b[A\nEpoch 1/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2639/2714 [00:09<00:00, 285.98batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2600] Loss: 1.0447\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 1/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2669/2714 [00:09<00:00, 288.06batch/s]\u001b[A\nEpoch 1/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2699/2714 [00:09<00:00, 290.81batch/s]\u001b[A\n                                                                   \nTraining Progress:   0%|          | 0/10 [00:09<?, ?epoch/s]atch/s]\u001b[A\nTraining Progress:  10%|â–ˆ         | 1/10 [00:09<01:25,  9.50s/epoch, avg_loss=1.4208]","output_type":"stream"},{"name":"stdout","text":"[Step 2700] Loss: 1.0389\nEpoch 1/10 completed | Avg Loss: 1.4208\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 2/10:   1%|          | 30/2714 [00:00<00:09, 295.46batch/s]\u001b[A\nEpoch 2/10:   2%|â–         | 60/2714 [00:00<00:08, 295.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:09<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:   3%|â–Ž         | 90/2714 [00:00<00:09, 284.09batch/s]\u001b[A\nEpoch 2/10:   4%|â–         | 120/2714 [00:00<00:08, 288.95batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2800] Loss: 1.4405\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:   6%|â–Œ         | 150/2714 [00:00<00:08, 290.35batch/s]\u001b[A\nEpoch 2/10:   7%|â–‹         | 180/2714 [00:00<00:08, 290.98batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:10<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:   8%|â–Š         | 210/2714 [00:00<00:08, 278.40batch/s]\u001b[A\nEpoch 2/10:   9%|â–‰         | 239/2714 [00:00<00:08, 279.40batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 2900] Loss: 1.6681\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  10%|â–‰         | 269/2714 [00:00<00:08, 283.46batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:10<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  11%|â–ˆ         | 298/2714 [00:01<00:09, 263.70batch/s]\u001b[A\nEpoch 2/10:  12%|â–ˆâ–        | 327/2714 [00:01<00:08, 270.99batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3000] Loss: 1.5801\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  13%|â–ˆâ–Ž        | 356/2714 [00:01<00:08, 274.20batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:10<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  14%|â–ˆâ–        | 386/2714 [00:01<00:08, 276.77batch/s]\u001b[A\nEpoch 2/10:  15%|â–ˆâ–Œ        | 416/2714 [00:01<00:08, 281.69batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3100] Loss: 1.3339\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  16%|â–ˆâ–‹        | 446/2714 [00:01<00:07, 285.82batch/s]\u001b[A\nEpoch 2/10:  18%|â–ˆâ–Š        | 476/2714 [00:01<00:07, 289.58batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:11<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  19%|â–ˆâ–Š        | 506/2714 [00:01<00:07, 286.15batch/s]\u001b[A\nEpoch 2/10:  20%|â–ˆâ–‰        | 536/2714 [00:01<00:07, 289.08batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3200] Loss: 1.3920\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  21%|â–ˆâ–ˆ        | 566/2714 [00:01<00:07, 289.89batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:11<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  22%|â–ˆâ–ˆâ–       | 596/2714 [00:02<00:07, 285.05batch/s]\u001b[A\nEpoch 2/10:  23%|â–ˆâ–ˆâ–Ž       | 626/2714 [00:02<00:07, 288.05batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3300] Loss: 1.0268\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  24%|â–ˆâ–ˆâ–       | 655/2714 [00:02<00:07, 287.10batch/s]\u001b[A\nEpoch 2/10:  25%|â–ˆâ–ˆâ–Œ       | 684/2714 [00:02<00:07, 286.18batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:11<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  26%|â–ˆâ–ˆâ–‹       | 713/2714 [00:02<00:07, 280.02batch/s]\u001b[A\nEpoch 2/10:  27%|â–ˆâ–ˆâ–‹       | 742/2714 [00:02<00:07, 280.44batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3400] Loss: 1.1362\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  28%|â–ˆâ–ˆâ–Š       | 772/2714 [00:02<00:06, 283.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:12<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  30%|â–ˆâ–ˆâ–‰       | 801/2714 [00:02<00:06, 281.78batch/s]\u001b[A\nEpoch 2/10:  31%|â–ˆâ–ˆâ–ˆ       | 831/2714 [00:02<00:06, 285.40batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3500] Loss: 1.5146\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 860/2714 [00:03<00:06, 283.18batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:12<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 889/2714 [00:03<00:06, 280.05batch/s]\u001b[A\nEpoch 2/10:  34%|â–ˆâ–ˆâ–ˆâ–      | 919/2714 [00:03<00:06, 283.71batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3600] Loss: 1.2055\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 948/2714 [00:03<00:06, 285.20batch/s]\u001b[A\nEpoch 2/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 978/2714 [00:03<00:06, 288.85batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:12<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1007/2714 [00:03<00:05, 284.72batch/s]\u001b[A\nEpoch 2/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1037/2714 [00:03<00:05, 288.74batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3700] Loss: 1.4178\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1067/2714 [00:03<00:05, 290.87batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:13<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1097/2714 [00:03<00:05, 286.67batch/s]\u001b[A\nEpoch 2/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1127/2714 [00:03<00:05, 290.42batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3800] Loss: 2.0054\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1157/2714 [00:04<00:05, 292.39batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:13<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1187/2714 [00:04<00:05, 288.18batch/s]\u001b[A\nEpoch 2/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1217/2714 [00:04<00:05, 290.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 3900] Loss: 0.9262\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1247/2714 [00:04<00:05, 290.74batch/s]\u001b[A\nEpoch 2/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1278/2714 [00:04<00:04, 293.61batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:14<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1308/2714 [00:04<00:04, 288.26batch/s]\u001b[A\nEpoch 2/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1338/2714 [00:04<00:04, 290.86batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4000] Loss: 1.8383\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1368/2714 [00:04<00:04, 290.70batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:14<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1398/2714 [00:04<00:04, 285.73batch/s]\u001b[A\nEpoch 2/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1428/2714 [00:05<00:04, 287.76batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4100] Loss: 1.5933\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1458/2714 [00:05<00:04, 289.21batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:14<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1487/2714 [00:05<00:04, 284.27batch/s]\u001b[A\nEpoch 2/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1517/2714 [00:05<00:04, 287.15batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4200] Loss: 1.3162\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1547/2714 [00:05<00:04, 288.28batch/s]\u001b[A\nEpoch 2/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1577/2714 [00:05<00:03, 289.21batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:15<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1606/2714 [00:05<00:03, 286.22batch/s]\u001b[A\nEpoch 2/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1636/2714 [00:05<00:03, 288.49batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4300] Loss: 1.7841\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1666/2714 [00:05<00:03, 290.23batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:15<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1696/2714 [00:05<00:03, 284.50batch/s]\u001b[A\nEpoch 2/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1726/2714 [00:06<00:03, 287.41batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4400] Loss: 1.2289\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1755/2714 [00:06<00:03, 287.13batch/s]\u001b[A\nEpoch 2/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1785/2714 [00:06<00:03, 288.08batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:15<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1814/2714 [00:06<00:03, 282.58batch/s]\u001b[A\nEpoch 2/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1843/2714 [00:06<00:03, 284.71batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4500] Loss: 1.7248\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1872/2714 [00:06<00:02, 286.24batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:16<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1901/2714 [00:06<00:02, 281.89batch/s]\u001b[A\nEpoch 2/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1931/2714 [00:06<00:02, 285.59batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4600] Loss: 0.8202\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1961/2714 [00:06<00:02, 287.56batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:16<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1990/2714 [00:06<00:02, 282.46batch/s]\u001b[A\nEpoch 2/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2020/2714 [00:07<00:02, 285.86batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4700] Loss: 1.2350\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2049/2714 [00:07<00:02, 286.40batch/s]\u001b[A\nEpoch 2/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2078/2714 [00:07<00:02, 287.13batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:16<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2107/2714 [00:07<00:02, 282.53batch/s]\u001b[A\nEpoch 2/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2136/2714 [00:07<00:02, 284.49batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4800] Loss: 1.4076\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2166/2714 [00:07<00:01, 287.36batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:17<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2195/2714 [00:07<00:01, 284.99batch/s]\u001b[A\nEpoch 2/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2224/2714 [00:07<00:01, 286.31batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 4900] Loss: 0.6602\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2254/2714 [00:07<00:01, 287.85batch/s]\u001b[A\nEpoch 2/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2284/2714 [00:07<00:01, 289.74batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:17<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2313/2714 [00:08<00:01, 283.94batch/s]\u001b[A\nEpoch 2/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2343/2714 [00:08<00:01, 287.80batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5000] Loss: 1.1716\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2372/2714 [00:08<00:01, 286.79batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:17<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2401/2714 [00:08<00:01, 281.98batch/s]\u001b[A\nEpoch 2/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2430/2714 [00:08<00:01, 283.99batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5100] Loss: 1.1379\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2459/2714 [00:08<00:00, 284.34batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:18<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2488/2714 [00:08<00:00, 280.97batch/s]\u001b[A\nEpoch 2/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2518/2714 [00:08<00:00, 284.55batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5200] Loss: 1.4795\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2548/2714 [00:08<00:00, 287.12batch/s]\u001b[A\nEpoch 2/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2578/2714 [00:09<00:00, 289.18batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:18<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2607/2714 [00:09<00:00, 283.94batch/s]\u001b[A\nEpoch 2/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2636/2714 [00:09<00:00, 284.91batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5300] Loss: 0.5671\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 2/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2665/2714 [00:09<00:00, 285.00batch/s]\u001b[A\n                                                                                     \nTraining Progress:  10%|â–ˆ         | 1/10 [00:18<01:25,  9.50s/epoch, avg_loss=1.4208]\nEpoch 2/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2694/2714 [00:09<00:00, 281.15batch/s]\u001b[A\nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/epoch, avg_loss=1.3661]","output_type":"stream"},{"name":"stdout","text":"[Step 5400] Loss: 1.7730\nEpoch 2/10 completed | Avg Loss: 1.3661\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 3/10:   1%|          | 30/2714 [00:00<00:08, 298.63batch/s]\u001b[A\nEpoch 3/10:   2%|â–         | 60/2714 [00:00<00:09, 294.75batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:   3%|â–Ž         | 90/2714 [00:00<00:09, 284.81batch/s]\u001b[A\nEpoch 3/10:   4%|â–         | 120/2714 [00:00<00:08, 290.42batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5500] Loss: 1.3928\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:   6%|â–Œ         | 150/2714 [00:00<00:08, 291.93batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:   7%|â–‹         | 180/2714 [00:00<00:08, 288.35batch/s]\u001b[A\nEpoch 3/10:   8%|â–Š         | 210/2714 [00:00<00:08, 291.43batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5600] Loss: 1.2181\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:   9%|â–‰         | 240/2714 [00:00<00:08, 292.66batch/s]\u001b[A\nEpoch 3/10:  10%|â–‰         | 270/2714 [00:00<00:08, 293.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:19<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  11%|â–ˆ         | 300/2714 [00:01<00:08, 287.67batch/s]\u001b[A\nEpoch 3/10:  12%|â–ˆâ–        | 330/2714 [00:01<00:08, 289.51batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5700] Loss: 1.2990\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  13%|â–ˆâ–Ž        | 359/2714 [00:01<00:08, 287.86batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:20<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  14%|â–ˆâ–        | 388/2714 [00:01<00:08, 283.29batch/s]\u001b[A\nEpoch 3/10:  15%|â–ˆâ–Œ        | 418/2714 [00:01<00:07, 287.66batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5800] Loss: 1.2732\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  16%|â–ˆâ–‹        | 447/2714 [00:01<00:08, 272.68batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:20<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  18%|â–ˆâ–Š        | 475/2714 [00:01<00:08, 272.28batch/s]\u001b[A\nEpoch 3/10:  19%|â–ˆâ–Š        | 504/2714 [00:01<00:07, 276.63batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 5900] Loss: 1.2280\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  20%|â–ˆâ–‰        | 534/2714 [00:01<00:07, 281.27batch/s]\u001b[A\nEpoch 3/10:  21%|â–ˆâ–ˆ        | 564/2714 [00:01<00:07, 284.27batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:21<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  22%|â–ˆâ–ˆâ–       | 593/2714 [00:02<00:07, 282.86batch/s]\u001b[A\nEpoch 3/10:  23%|â–ˆâ–ˆâ–Ž       | 622/2714 [00:02<00:07, 284.76batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6000] Loss: 1.4004\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  24%|â–ˆâ–ˆâ–       | 652/2714 [00:02<00:07, 286.48batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:21<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  25%|â–ˆâ–ˆâ–Œ       | 681/2714 [00:02<00:07, 275.53batch/s]\u001b[A\nEpoch 3/10:  26%|â–ˆâ–ˆâ–Œ       | 709/2714 [00:02<00:07, 273.76batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6100] Loss: 1.0203\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  27%|â–ˆâ–ˆâ–‹       | 737/2714 [00:02<00:07, 275.32batch/s]\u001b[A\nEpoch 3/10:  28%|â–ˆâ–ˆâ–Š       | 766/2714 [00:02<00:06, 279.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:21<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  29%|â–ˆâ–ˆâ–‰       | 795/2714 [00:02<00:07, 271.12batch/s]\u001b[A\nEpoch 3/10:  30%|â–ˆâ–ˆâ–ˆ       | 823/2714 [00:02<00:07, 270.02batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6200] Loss: 0.6291\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  31%|â–ˆâ–ˆâ–ˆâ–      | 851/2714 [00:03<00:06, 271.29batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:22<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 879/2714 [00:03<00:06, 263.52batch/s]\u001b[A\nEpoch 3/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 909/2714 [00:03<00:06, 271.83batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6300] Loss: 1.2942\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 938/2714 [00:03<00:06, 276.39batch/s]\u001b[A\nEpoch 3/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 967/2714 [00:03<00:06, 279.90batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:22<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 996/2714 [00:03<00:06, 279.15batch/s]\u001b[A\nEpoch 3/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1026/2714 [00:03<00:05, 284.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6400] Loss: 1.4960\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1055/2714 [00:03<00:05, 286.05batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:22<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1084/2714 [00:03<00:05, 281.74batch/s]\u001b[A\nEpoch 3/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1114/2714 [00:03<00:05, 285.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6500] Loss: 2.0256\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1144/2714 [00:04<00:05, 288.13batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:23<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1173/2714 [00:04<00:05, 286.18batch/s]\u001b[A\nEpoch 3/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1203/2714 [00:04<00:05, 290.09batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6600] Loss: 1.2379\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1233/2714 [00:04<00:05, 286.58batch/s]\u001b[A\nEpoch 3/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1264/2714 [00:04<00:04, 290.84batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:23<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1294/2714 [00:04<00:04, 287.34batch/s]\u001b[A\nEpoch 3/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1324/2714 [00:04<00:04, 290.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6700] Loss: 1.0227\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1354/2714 [00:04<00:04, 291.01batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:23<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1384/2714 [00:04<00:04, 287.92batch/s]\u001b[A\nEpoch 3/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1414/2714 [00:04<00:04, 288.85batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6800] Loss: 0.6817\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1444/2714 [00:05<00:04, 289.29batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:24<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1473/2714 [00:05<00:04, 284.38batch/s]\u001b[A\nEpoch 3/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1503/2714 [00:05<00:04, 288.82batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 6900] Loss: 1.2104\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1534/2714 [00:05<00:04, 291.84batch/s]\u001b[A\nEpoch 3/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1565/2714 [00:05<00:03, 294.64batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:24<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1595/2714 [00:05<00:03, 290.89batch/s]\u001b[A\nEpoch 3/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1625/2714 [00:05<00:03, 292.52batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7000] Loss: 1.6740\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1655/2714 [00:05<00:03, 290.29batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:24<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1685/2714 [00:05<00:03, 284.31batch/s]\u001b[A\nEpoch 3/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1715/2714 [00:06<00:03, 286.77batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7100] Loss: 1.2026\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1744/2714 [00:06<00:03, 287.09batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:25<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1773/2714 [00:06<00:03, 281.84batch/s]\u001b[A\nEpoch 3/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1803/2714 [00:06<00:03, 286.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7200] Loss: 1.4976\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1833/2714 [00:06<00:03, 288.24batch/s]\u001b[A\nEpoch 3/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1863/2714 [00:06<00:02, 290.88batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:25<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1893/2714 [00:06<00:02, 285.58batch/s]\u001b[A\nEpoch 3/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1922/2714 [00:06<00:02, 286.66batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7300] Loss: 1.5241\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1951/2714 [00:06<00:02, 286.66batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:25<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1980/2714 [00:06<00:02, 281.81batch/s]\u001b[A\nEpoch 3/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2009/2714 [00:07<00:02, 283.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7400] Loss: 1.0356\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2038/2714 [00:07<00:02, 285.52batch/s]\u001b[A\nEpoch 3/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2068/2714 [00:07<00:02, 288.40batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:26<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2097/2714 [00:07<00:02, 283.74batch/s]\u001b[A\nEpoch 3/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2127/2714 [00:07<00:02, 286.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7500] Loss: 1.6391\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2157/2714 [00:07<00:01, 287.83batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:26<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2186/2714 [00:07<00:01, 283.75batch/s]\u001b[A\nEpoch 3/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2216/2714 [00:07<00:01, 287.33batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7600] Loss: 1.2240\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2246/2714 [00:07<00:01, 289.65batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:26<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2275/2714 [00:07<00:01, 285.81batch/s]\u001b[A\nEpoch 3/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2305/2714 [00:08<00:01, 288.93batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7700] Loss: 1.0528\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2335/2714 [00:08<00:01, 291.85batch/s]\u001b[A\nEpoch 3/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2365/2714 [00:08<00:01, 293.14batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:27<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2395/2714 [00:08<00:01, 285.60batch/s]\u001b[A\nEpoch 3/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2425/2714 [00:08<00:01, 287.52batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7800] Loss: 1.4847\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2455/2714 [00:08<00:00, 288.59batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:27<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2484/2714 [00:08<00:00, 284.38batch/s]\u001b[A\nEpoch 3/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2513/2714 [00:08<00:00, 284.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 7900] Loss: 0.9914\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2542/2714 [00:08<00:00, 285.89batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:28<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2572/2714 [00:09<00:00, 283.67batch/s]\u001b[A\nEpoch 3/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2601/2714 [00:09<00:00, 284.47batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8000] Loss: 1.0773\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 3/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2630/2714 [00:09<00:00, 285.66batch/s]\u001b[A\nEpoch 3/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2660/2714 [00:09<00:00, 288.73batch/s]\u001b[A\n                                                                                     \nTraining Progress:  20%|â–ˆâ–ˆ        | 2/10 [00:28<01:16,  9.51s/epoch, avg_loss=1.3661]\nEpoch 3/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2689/2714 [00:09<00:00, 285.80batch/s]\u001b[A\nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:28<01:06,  9.52s/epoch, avg_loss=1.3141]","output_type":"stream"},{"name":"stdout","text":"[Step 8100] Loss: 1.3651\nEpoch 3/10 completed | Avg Loss: 1.3141\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 4/10:   1%|          | 30/2714 [00:00<00:09, 297.36batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:28<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:   2%|â–         | 60/2714 [00:00<00:09, 281.24batch/s]\u001b[A\nEpoch 4/10:   3%|â–Ž         | 90/2714 [00:00<00:09, 286.43batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8200] Loss: 0.9340\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:   4%|â–         | 120/2714 [00:00<00:08, 289.91batch/s]\u001b[A\nEpoch 4/10:   6%|â–Œ         | 150/2714 [00:00<00:08, 293.19batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:29<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:   7%|â–‹         | 180/2714 [00:00<00:08, 286.65batch/s]\u001b[A\nEpoch 4/10:   8%|â–Š         | 209/2714 [00:00<00:08, 287.62batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8300] Loss: 1.5514\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:   9%|â–‰         | 238/2714 [00:00<00:08, 288.16batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:29<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  10%|â–‰         | 267/2714 [00:00<00:08, 283.09batch/s]\u001b[A\nEpoch 4/10:  11%|â–ˆ         | 296/2714 [00:01<00:08, 285.00batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8400] Loss: 0.9723\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  12%|â–ˆâ–        | 325/2714 [00:01<00:08, 285.96batch/s]\u001b[A\nEpoch 4/10:  13%|â–ˆâ–Ž        | 355/2714 [00:01<00:08, 287.25batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:29<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  14%|â–ˆâ–        | 384/2714 [00:01<00:08, 282.93batch/s]\u001b[A\nEpoch 4/10:  15%|â–ˆâ–Œ        | 414/2714 [00:01<00:07, 287.84batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8500] Loss: 1.0041\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  16%|â–ˆâ–‹        | 444/2714 [00:01<00:07, 290.45batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  17%|â–ˆâ–‹        | 474/2714 [00:01<00:07, 284.17batch/s]\u001b[A\nEpoch 4/10:  19%|â–ˆâ–Š        | 503/2714 [00:01<00:07, 283.69batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8600] Loss: 1.4615\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  20%|â–ˆâ–‰        | 532/2714 [00:01<00:07, 284.36batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  21%|â–ˆâ–ˆ        | 561/2714 [00:01<00:07, 275.65batch/s]\u001b[A\nEpoch 4/10:  22%|â–ˆâ–ˆâ–       | 589/2714 [00:02<00:07, 270.25batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8700] Loss: 1.0388\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  23%|â–ˆâ–ˆâ–Ž       | 619/2714 [00:02<00:07, 277.22batch/s]\u001b[A\nEpoch 4/10:  24%|â–ˆâ–ˆâ–       | 649/2714 [00:02<00:07, 282.27batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:30<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  25%|â–ˆâ–ˆâ–       | 678/2714 [00:02<00:07, 278.08batch/s]\u001b[A\nEpoch 4/10:  26%|â–ˆâ–ˆâ–Œ       | 708/2714 [00:02<00:07, 283.53batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8800] Loss: 1.1759\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  27%|â–ˆâ–ˆâ–‹       | 737/2714 [00:02<00:06, 283.55batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:31<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  28%|â–ˆâ–ˆâ–Š       | 766/2714 [00:02<00:06, 279.35batch/s]\u001b[A\nEpoch 4/10:  29%|â–ˆâ–ˆâ–‰       | 795/2714 [00:02<00:06, 282.39batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 8900] Loss: 1.4616\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  30%|â–ˆâ–ˆâ–ˆ       | 824/2714 [00:02<00:06, 283.70batch/s]\u001b[A\nEpoch 4/10:  31%|â–ˆâ–ˆâ–ˆâ–      | 854/2714 [00:03<00:06, 286.17batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:31<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 883/2714 [00:03<00:06, 283.26batch/s]\u001b[A\nEpoch 4/10:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 913/2714 [00:03<00:06, 287.48batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9000] Loss: 0.8906\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 942/2714 [00:03<00:06, 287.11batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:31<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 971/2714 [00:03<00:06, 282.60batch/s]\u001b[A\nEpoch 4/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1001/2714 [00:03<00:05, 285.91batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9100] Loss: 1.0396\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1030/2714 [00:03<00:05, 286.69batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1059/2714 [00:03<00:05, 283.21batch/s]\u001b[A\nEpoch 4/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1088/2714 [00:03<00:05, 284.66batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9200] Loss: 1.4548\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1117/2714 [00:03<00:05, 285.55batch/s]\u001b[A\nEpoch 4/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1147/2714 [00:04<00:05, 288.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1176/2714 [00:04<00:05, 285.66batch/s]\u001b[A\nEpoch 4/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1206/2714 [00:04<00:05, 289.67batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9300] Loss: 1.1655\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1236/2714 [00:04<00:05, 291.74batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:32<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1266/2714 [00:04<00:05, 287.55batch/s]\u001b[A\nEpoch 4/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1296/2714 [00:04<00:04, 290.57batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9400] Loss: 1.3716\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1326/2714 [00:04<00:04, 292.65batch/s]\u001b[A\nEpoch 4/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1357/2714 [00:04<00:04, 295.41batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:33<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1387/2714 [00:04<00:04, 288.03batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9500] Loss: 0.9736\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1417/2714 [00:04<00:04, 290.33batch/s]\u001b[A\nEpoch 4/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1447/2714 [00:05<00:04, 292.43batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:33<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1477/2714 [00:05<00:04, 288.27batch/s]\u001b[A\nEpoch 4/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1507/2714 [00:05<00:04, 291.02batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9600] Loss: 1.4454\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1537/2714 [00:05<00:04, 291.84batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:33<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1567/2714 [00:05<00:03, 286.82batch/s]\u001b[A\nEpoch 4/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1597/2714 [00:05<00:03, 289.57batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9700] Loss: 1.1094\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1627/2714 [00:05<00:03, 290.09batch/s]\u001b[A\nEpoch 4/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1657/2714 [00:05<00:03, 290.46batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:34<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1687/2714 [00:05<00:03, 285.50batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9800] Loss: 1.3235\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1717/2714 [00:05<00:03, 288.23batch/s]\u001b[A\nEpoch 4/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1747/2714 [00:06<00:03, 290.73batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:34<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1777/2714 [00:06<00:03, 286.90batch/s]\u001b[A\nEpoch 4/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1808/2714 [00:06<00:03, 286.63batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 9900] Loss: 1.2091\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1838/2714 [00:06<00:03, 287.87batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:35<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1867/2714 [00:06<00:02, 284.13batch/s]\u001b[A\nEpoch 4/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1897/2714 [00:06<00:02, 287.24batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10000] Loss: 0.9997\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1927/2714 [00:06<00:02, 290.64batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:35<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1958/2714 [00:06<00:02, 289.26batch/s]\u001b[A\nEpoch 4/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1987/2714 [00:06<00:02, 288.39batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10100] Loss: 1.2218\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2017/2714 [00:07<00:02, 291.54batch/s]\u001b[A\nEpoch 4/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2048/2714 [00:07<00:02, 294.06batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:35<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2078/2714 [00:07<00:02, 288.79batch/s]\u001b[A\nEpoch 4/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2108/2714 [00:07<00:02, 289.75batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10200] Loss: 1.4088\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2138/2714 [00:07<00:01, 290.94batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2168/2714 [00:07<00:01, 285.52batch/s]\u001b[A\nEpoch 4/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2198/2714 [00:07<00:01, 287.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10300] Loss: 1.3703\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2228/2714 [00:07<00:01, 289.05batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2258/2714 [00:07<00:01, 284.63batch/s]\u001b[A\nEpoch 4/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2288/2714 [00:07<00:01, 286.93batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10400] Loss: 1.5246\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2317/2714 [00:08<00:01, 287.30batch/s]\u001b[A\nEpoch 4/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2347/2714 [00:08<00:01, 288.22batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:36<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2376/2714 [00:08<00:01, 283.57batch/s]\u001b[A\nEpoch 4/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2406/2714 [00:08<00:01, 286.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10500] Loss: 1.1377\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2436/2714 [00:08<00:00, 290.07batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2466/2714 [00:08<00:00, 286.20batch/s]\u001b[A\nEpoch 4/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2496/2714 [00:08<00:00, 289.94batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10600] Loss: 1.3872\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2526/2714 [00:08<00:00, 292.06batch/s]\u001b[A\nEpoch 4/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2556/2714 [00:08<00:00, 292.35batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2586/2714 [00:09<00:00, 287.66batch/s]\u001b[A\nEpoch 4/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2617/2714 [00:09<00:00, 291.86batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10700] Loss: 0.9785\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 4/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2647/2714 [00:09<00:00, 292.95batch/s]\u001b[A\n                                                                                     \nTraining Progress:  30%|â–ˆâ–ˆâ–ˆ       | 3/10 [00:37<01:06,  9.52s/epoch, avg_loss=1.3141]\nEpoch 4/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2677/2714 [00:09<00:00, 286.57batch/s]\u001b[A\nEpoch 4/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2707/2714 [00:09<00:00, 290.40batch/s]\u001b[A\n                                                                                     \r","output_type":"stream"},{"name":"stdout","text":"[Step 10800] Loss: 1.3946\nEpoch 4/10 completed | Avg Loss: 1.2619\n","output_type":"stream"},{"name":"stderr","text":"Training Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 5/10:   1%|          | 30/2714 [00:00<00:09, 297.97batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:   2%|â–         | 60/2714 [00:00<00:09, 285.86batch/s]\u001b[A\nEpoch 5/10:   3%|â–Ž         | 91/2714 [00:00<00:08, 293.53batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 10900] Loss: 1.1703\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:   4%|â–         | 121/2714 [00:00<00:08, 295.07batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:   6%|â–Œ         | 151/2714 [00:00<00:08, 286.53batch/s]\u001b[A\nEpoch 5/10:   7%|â–‹         | 181/2714 [00:00<00:08, 289.52batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11000] Loss: 1.1626\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:   8%|â–Š         | 211/2714 [00:00<00:08, 292.43batch/s]\u001b[A\nEpoch 5/10:   9%|â–‰         | 241/2714 [00:00<00:08, 294.12batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:38<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  10%|â–‰         | 271/2714 [00:00<00:08, 288.15batch/s]\u001b[A\nEpoch 5/10:  11%|â–ˆ         | 301/2714 [00:01<00:08, 290.32batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11100] Loss: 1.1219\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  12%|â–ˆâ–        | 332/2714 [00:01<00:08, 294.26batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:39<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  13%|â–ˆâ–Ž        | 362/2714 [00:01<00:08, 288.22batch/s]\u001b[A\nEpoch 5/10:  14%|â–ˆâ–        | 392/2714 [00:01<00:07, 290.26batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11200] Loss: 1.5577\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  16%|â–ˆâ–Œ        | 422/2714 [00:01<00:07, 290.48batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:39<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  17%|â–ˆâ–‹        | 452/2714 [00:01<00:07, 287.73batch/s]\u001b[A\nEpoch 5/10:  18%|â–ˆâ–Š        | 482/2714 [00:01<00:07, 289.62batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11300] Loss: 0.5435\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  19%|â–ˆâ–‰        | 512/2714 [00:01<00:07, 290.17batch/s]\u001b[A\nEpoch 5/10:  20%|â–ˆâ–‰        | 542/2714 [00:01<00:07, 292.41batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:39<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  21%|â–ˆâ–ˆ        | 572/2714 [00:01<00:07, 288.84batch/s]\u001b[A\nEpoch 5/10:  22%|â–ˆâ–ˆâ–       | 602/2714 [00:02<00:07, 290.81batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11400] Loss: 1.4010\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  23%|â–ˆâ–ˆâ–Ž       | 632/2714 [00:02<00:07, 292.22batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:40<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  24%|â–ˆâ–ˆâ–       | 662/2714 [00:02<00:07, 285.83batch/s]\u001b[A\nEpoch 5/10:  25%|â–ˆâ–ˆâ–Œ       | 692/2714 [00:02<00:06, 288.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11500] Loss: 0.5262\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  27%|â–ˆâ–ˆâ–‹       | 722/2714 [00:02<00:06, 290.36batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:40<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  28%|â–ˆâ–ˆâ–Š       | 752/2714 [00:02<00:07, 270.15batch/s]\u001b[A\nEpoch 5/10:  29%|â–ˆâ–ˆâ–‰       | 782/2714 [00:02<00:06, 278.00batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11600] Loss: 1.3262\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  30%|â–ˆâ–ˆâ–‰       | 812/2714 [00:02<00:06, 282.81batch/s]\u001b[A\nEpoch 5/10:  31%|â–ˆâ–ˆâ–ˆ       | 842/2714 [00:02<00:06, 286.82batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:40<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 871/2714 [00:03<00:06, 284.62batch/s]\u001b[A\nEpoch 5/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 902/2714 [00:03<00:06, 289.37batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11700] Loss: 0.9703\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  34%|â–ˆâ–ˆâ–ˆâ–      | 932/2714 [00:03<00:06, 292.06batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:41<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 962/2714 [00:03<00:06, 287.85batch/s]\u001b[A\nEpoch 5/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 993/2714 [00:03<00:05, 291.60batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11800] Loss: 1.0678\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1023/2714 [00:03<00:05, 291.76batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:41<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1053/2714 [00:03<00:05, 287.03batch/s]\u001b[A\nEpoch 5/10:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1083/2714 [00:03<00:05, 289.61batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 11900] Loss: 1.2858\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1113/2714 [00:03<00:05, 290.00batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:41<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1144/2714 [00:03<00:05, 289.12batch/s]\u001b[A\nEpoch 5/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1173/2714 [00:04<00:05, 288.15batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12000] Loss: 1.3798\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1202/2714 [00:04<00:05, 286.05batch/s]\u001b[A\nEpoch 5/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1232/2714 [00:04<00:05, 288.69batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:42<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1261/2714 [00:04<00:05, 283.83batch/s]\u001b[A\nEpoch 5/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1290/2714 [00:04<00:05, 278.17batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12100] Loss: 1.2947\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1318/2714 [00:04<00:05, 274.42batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:42<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1346/2714 [00:04<00:04, 273.87batch/s]\u001b[A\nEpoch 5/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1376/2714 [00:04<00:04, 279.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12200] Loss: 1.7223\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1405/2714 [00:04<00:04, 282.46batch/s]\u001b[A\nEpoch 5/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1435/2714 [00:04<00:04, 285.74batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:43<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1464/2714 [00:05<00:04, 281.52batch/s]\u001b[A\nEpoch 5/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1494/2714 [00:05<00:04, 284.56batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12300] Loss: 1.4903\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1523/2714 [00:05<00:04, 285.31batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:43<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1552/2714 [00:05<00:04, 279.23batch/s]\u001b[A\nEpoch 5/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1582/2714 [00:05<00:03, 283.16batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12400] Loss: 0.9324\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1611/2714 [00:05<00:03, 285.01batch/s]\u001b[A\nEpoch 5/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1641/2714 [00:05<00:03, 287.27batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:43<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1670/2714 [00:05<00:03, 282.30batch/s]\u001b[A\nEpoch 5/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1699/2714 [00:05<00:03, 284.26batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12500] Loss: 1.4166\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1728/2714 [00:06<00:03, 284.98batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1757/2714 [00:06<00:03, 280.11batch/s]\u001b[A\nEpoch 5/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1786/2714 [00:06<00:03, 282.73batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12600] Loss: 1.2052\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1816/2714 [00:06<00:03, 285.76batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1845/2714 [00:06<00:03, 282.45batch/s]\u001b[A\nEpoch 5/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1875/2714 [00:06<00:02, 286.78batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12700] Loss: 1.1149\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1905/2714 [00:06<00:02, 288.60batch/s]\u001b[A\nEpoch 5/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1935/2714 [00:06<00:02, 290.47batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:44<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1965/2714 [00:06<00:02, 282.84batch/s]\u001b[A\nEpoch 5/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1995/2714 [00:06<00:02, 285.23batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12800] Loss: 1.4621\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2024/2714 [00:07<00:02, 286.25batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2053/2714 [00:07<00:02, 279.73batch/s]\u001b[A\nEpoch 5/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2082/2714 [00:07<00:02, 282.55batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 12900] Loss: 1.1542\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2111/2714 [00:07<00:02, 280.55batch/s]\u001b[A\nEpoch 5/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2140/2714 [00:07<00:02, 282.87batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2169/2714 [00:07<00:01, 278.02batch/s]\u001b[A\nEpoch 5/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2198/2714 [00:07<00:01, 280.39batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13000] Loss: 1.3169\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2227/2714 [00:07<00:01, 282.12batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:45<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2256/2714 [00:07<00:01, 276.92batch/s]\u001b[A\nEpoch 5/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2286/2714 [00:08<00:01, 280.89batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13100] Loss: 0.9276\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2315/2714 [00:08<00:01, 282.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:46<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2344/2714 [00:08<00:01, 280.24batch/s]\u001b[A\nEpoch 5/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2374/2714 [00:08<00:01, 284.23batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13200] Loss: 1.7834\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2403/2714 [00:08<00:01, 285.71batch/s]\u001b[A\nEpoch 5/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2433/2714 [00:08<00:00, 287.47batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:46<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2462/2714 [00:08<00:00, 283.91batch/s]\u001b[A\nEpoch 5/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2492/2714 [00:08<00:00, 286.57batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13300] Loss: 1.0363\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2522/2714 [00:08<00:00, 288.44batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:46<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2551/2714 [00:08<00:00, 282.45batch/s]\u001b[A\nEpoch 5/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2581/2714 [00:09<00:00, 287.21batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13400] Loss: 1.2004\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2611/2714 [00:09<00:00, 288.96batch/s]\u001b[A\nEpoch 5/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2641/2714 [00:09<00:00, 291.14batch/s]\u001b[A\n                                                                                     \nTraining Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [00:47<00:56,  9.50s/epoch, avg_loss=1.2619]\nEpoch 5/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2671/2714 [00:09<00:00, 282.17batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13500] Loss: 1.2520\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 5/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2701/2714 [00:09<00:00, 285.02batch/s]\u001b[A\nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:47<00:47,  9.50s/epoch, avg_loss=1.2085]","output_type":"stream"},{"name":"stdout","text":"Epoch 5/10 completed | Avg Loss: 1.2085\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:47<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:   1%|          | 30/2714 [00:00<00:09, 280.67batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13600] Loss: 1.2620\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:   2%|â–         | 60/2714 [00:00<00:09, 286.60batch/s]\u001b[A\nEpoch 6/10:   3%|â–Ž         | 90/2714 [00:00<00:09, 290.35batch/s]\u001b[A\nEpoch 6/10:   4%|â–         | 120/2714 [00:00<00:08, 289.34batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:47<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:   5%|â–Œ         | 149/2714 [00:00<00:09, 283.57batch/s]\u001b[A\nEpoch 6/10:   7%|â–‹         | 179/2714 [00:00<00:08, 287.47batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13700] Loss: 1.0600\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:   8%|â–Š         | 209/2714 [00:00<00:08, 290.27batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:48<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:   9%|â–‰         | 239/2714 [00:00<00:08, 283.70batch/s]\u001b[A\nEpoch 6/10:  10%|â–‰         | 269/2714 [00:00<00:08, 286.08batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13800] Loss: 1.7817\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  11%|â–ˆ         | 298/2714 [00:01<00:08, 286.03batch/s]\u001b[A\nEpoch 6/10:  12%|â–ˆâ–        | 328/2714 [00:01<00:08, 288.13batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:48<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  13%|â–ˆâ–Ž        | 357/2714 [00:01<00:08, 283.18batch/s]\u001b[A\nEpoch 6/10:  14%|â–ˆâ–        | 386/2714 [00:01<00:08, 284.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 13900] Loss: 1.3088\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  15%|â–ˆâ–Œ        | 416/2714 [00:01<00:08, 286.06batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:49<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  16%|â–ˆâ–‹        | 445/2714 [00:01<00:08, 281.12batch/s]\u001b[A\nEpoch 6/10:  17%|â–ˆâ–‹        | 474/2714 [00:01<00:07, 282.79batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14000] Loss: 0.9685\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  19%|â–ˆâ–Š        | 503/2714 [00:01<00:07, 283.82batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:49<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  20%|â–ˆâ–‰        | 532/2714 [00:01<00:07, 280.18batch/s]\u001b[A\nEpoch 6/10:  21%|â–ˆâ–ˆ        | 561/2714 [00:01<00:07, 282.18batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14100] Loss: 1.6583\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  22%|â–ˆâ–ˆâ–       | 590/2714 [00:02<00:07, 282.98batch/s]\u001b[A\nEpoch 6/10:  23%|â–ˆâ–ˆâ–Ž       | 619/2714 [00:02<00:07, 284.13batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:49<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  24%|â–ˆâ–ˆâ–       | 648/2714 [00:02<00:07, 280.58batch/s]\u001b[A\nEpoch 6/10:  25%|â–ˆâ–ˆâ–       | 678/2714 [00:02<00:07, 283.74batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14200] Loss: 1.0659\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  26%|â–ˆâ–ˆâ–Œ       | 708/2714 [00:02<00:07, 286.54batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:50<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  27%|â–ˆâ–ˆâ–‹       | 737/2714 [00:02<00:07, 280.93batch/s]\u001b[A\nEpoch 6/10:  28%|â–ˆâ–ˆâ–Š       | 766/2714 [00:02<00:06, 280.33batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14300] Loss: 1.7692\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  29%|â–ˆâ–ˆâ–‰       | 795/2714 [00:02<00:06, 281.50batch/s]\u001b[A\nEpoch 6/10:  30%|â–ˆâ–ˆâ–ˆ       | 824/2714 [00:02<00:06, 283.91batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:50<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  31%|â–ˆâ–ˆâ–ˆâ–      | 853/2714 [00:03<00:06, 270.67batch/s]\u001b[A\nEpoch 6/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 881/2714 [00:03<00:06, 271.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14400] Loss: 1.2077\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  34%|â–ˆâ–ˆâ–ˆâ–Ž      | 910/2714 [00:03<00:06, 273.90batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:50<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 938/2714 [00:03<00:06, 268.06batch/s]\u001b[A\nEpoch 6/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 966/2714 [00:03<00:06, 271.39batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14500] Loss: 1.3041\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 995/2714 [00:03<00:06, 276.29batch/s]\u001b[A\nEpoch 6/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1025/2714 [00:03<00:05, 282.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:51<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1054/2714 [00:03<00:05, 277.98batch/s]\u001b[A\nEpoch 6/10:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 1084/2714 [00:03<00:05, 282.24batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14600] Loss: 1.3155\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1113/2714 [00:03<00:05, 283.61batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:51<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1142/2714 [00:04<00:05, 279.84batch/s]\u001b[A\nEpoch 6/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1172/2714 [00:04<00:05, 284.61batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14700] Loss: 0.8346\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1201/2714 [00:04<00:05, 285.88batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:51<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1230/2714 [00:04<00:05, 278.44batch/s]\u001b[A\nEpoch 6/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1259/2714 [00:04<00:05, 281.12batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14800] Loss: 1.1945\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1288/2714 [00:04<00:05, 278.64batch/s]\u001b[A\nEpoch 6/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1317/2714 [00:04<00:04, 279.85batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:52<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1346/2714 [00:04<00:05, 270.73batch/s]\u001b[A\nEpoch 6/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1374/2714 [00:04<00:04, 272.72batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 14900] Loss: 1.0857\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1404/2714 [00:04<00:04, 278.49batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:52<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1432/2714 [00:05<00:04, 275.65batch/s]\u001b[A\nEpoch 6/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1463/2714 [00:05<00:04, 283.26batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15000] Loss: 1.3711\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1493/2714 [00:05<00:04, 286.35batch/s]\u001b[A\nEpoch 6/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1522/2714 [00:05<00:04, 286.54batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:52<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1551/2714 [00:05<00:04, 282.64batch/s]\u001b[A\nEpoch 6/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1581/2714 [00:05<00:03, 285.89batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15100] Loss: 1.0490\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1611/2714 [00:05<00:03, 287.55batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:53<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1640/2714 [00:05<00:03, 283.45batch/s]\u001b[A\nEpoch 6/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1669/2714 [00:05<00:03, 284.40batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15200] Loss: 1.0820\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1698/2714 [00:06<00:03, 283.84batch/s]\u001b[A\nEpoch 6/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1728/2714 [00:06<00:03, 285.84batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:53<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1757/2714 [00:06<00:03, 282.18batch/s]\u001b[A\nEpoch 6/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1787/2714 [00:06<00:03, 286.24batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15300] Loss: 1.6316\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1817/2714 [00:06<00:03, 287.91batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:54<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1846/2714 [00:06<00:03, 284.28batch/s]\u001b[A\nEpoch 6/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1877/2714 [00:06<00:02, 289.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15400] Loss: 0.9671\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1906/2714 [00:06<00:02, 287.95batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:54<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1935/2714 [00:06<00:02, 281.10batch/s]\u001b[A\nEpoch 6/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1965/2714 [00:06<00:02, 285.66batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15500] Loss: 1.6543\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1994/2714 [00:07<00:02, 285.07batch/s]\u001b[A\nEpoch 6/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2024/2714 [00:07<00:02, 287.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:54<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2053/2714 [00:07<00:02, 280.42batch/s]\u001b[A\nEpoch 6/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2083/2714 [00:07<00:02, 284.50batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15600] Loss: 0.5609\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2112/2714 [00:07<00:02, 285.57batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2141/2714 [00:07<00:02, 282.74batch/s]\u001b[A\nEpoch 6/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2171/2714 [00:07<00:01, 285.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15700] Loss: 1.6497\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2200/2714 [00:07<00:01, 286.09batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2230/2714 [00:07<00:01, 284.19batch/s]\u001b[A\nEpoch 6/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2260/2714 [00:07<00:01, 287.53batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15800] Loss: 1.1403\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2289/2714 [00:08<00:01, 287.70batch/s]\u001b[A\nEpoch 6/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2319/2714 [00:08<00:01, 288.90batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:55<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2348/2714 [00:08<00:01, 285.25batch/s]\u001b[A\nEpoch 6/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2378/2714 [00:08<00:01, 288.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 15900] Loss: 1.3499\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2408/2714 [00:08<00:01, 290.68batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2438/2714 [00:08<00:00, 286.32batch/s]\u001b[A\nEpoch 6/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2468/2714 [00:08<00:00, 290.00batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16000] Loss: 1.1221\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2498/2714 [00:08<00:00, 289.91batch/s]\u001b[A\nEpoch 6/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2528/2714 [00:08<00:00, 290.03batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2558/2714 [00:09<00:00, 285.28batch/s]\u001b[A\nEpoch 6/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2588/2714 [00:09<00:00, 287.85batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16100] Loss: 0.9003\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2617/2714 [00:09<00:00, 288.21batch/s]\u001b[A\n                                                                                     \nTraining Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 5/10 [00:56<00:47,  9.50s/epoch, avg_loss=1.2085]\nEpoch 6/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2646/2714 [00:09<00:00, 284.76batch/s]\u001b[A\nEpoch 6/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2675/2714 [00:09<00:00, 286.16batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16200] Loss: 1.1417\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 6/10: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2705/2714 [00:09<00:00, 288.23batch/s]\u001b[A\nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:57<00:38,  9.53s/epoch, avg_loss=1.1545]","output_type":"stream"},{"name":"stdout","text":"Epoch 6/10 completed | Avg Loss: 1.1545\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:57<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:   1%|          | 28/2714 [00:00<00:09, 274.64batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16300] Loss: 0.5086\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:   2%|â–         | 58/2714 [00:00<00:09, 286.30batch/s]\u001b[A\nEpoch 7/10:   3%|â–Ž         | 88/2714 [00:00<00:09, 290.85batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:57<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:   4%|â–         | 118/2714 [00:00<00:09, 283.73batch/s]\u001b[A\nEpoch 7/10:   5%|â–Œ         | 148/2714 [00:00<00:08, 286.75batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16400] Loss: 1.3533\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:   7%|â–‹         | 177/2714 [00:00<00:08, 287.69batch/s]\u001b[A\nEpoch 7/10:   8%|â–Š         | 207/2714 [00:00<00:08, 289.73batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:57<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:   9%|â–Š         | 236/2714 [00:00<00:08, 283.02batch/s]\u001b[A\nEpoch 7/10:  10%|â–‰         | 265/2714 [00:00<00:08, 285.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16500] Loss: 1.2080\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  11%|â–ˆ         | 295/2714 [00:01<00:08, 286.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:58<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  12%|â–ˆâ–        | 324/2714 [00:01<00:08, 282.16batch/s]\u001b[A\nEpoch 7/10:  13%|â–ˆâ–Ž        | 354/2714 [00:01<00:08, 284.70batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16600] Loss: 0.9174\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  14%|â–ˆâ–        | 383/2714 [00:01<00:08, 285.68batch/s]\u001b[A\nEpoch 7/10:  15%|â–ˆâ–Œ        | 413/2714 [00:01<00:08, 287.23batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:58<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  16%|â–ˆâ–‹        | 442/2714 [00:01<00:08, 282.98batch/s]\u001b[A\nEpoch 7/10:  17%|â–ˆâ–‹        | 471/2714 [00:01<00:07, 284.83batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16700] Loss: 0.8838\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  18%|â–ˆâ–Š        | 501/2714 [00:01<00:07, 287.54batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:58<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  20%|â–ˆâ–‰        | 530/2714 [00:01<00:07, 282.28batch/s]\u001b[A\nEpoch 7/10:  21%|â–ˆâ–ˆ        | 561/2714 [00:01<00:07, 287.81batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16800] Loss: 1.0223\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  22%|â–ˆâ–ˆâ–       | 591/2714 [00:02<00:07, 289.83batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  23%|â–ˆâ–ˆâ–Ž       | 620/2714 [00:02<00:07, 287.90batch/s]\u001b[A\nEpoch 7/10:  24%|â–ˆâ–ˆâ–       | 650/2714 [00:02<00:07, 290.82batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 16900] Loss: 1.3363\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  25%|â–ˆâ–ˆâ–Œ       | 681/2714 [00:02<00:06, 293.91batch/s]\u001b[A\nEpoch 7/10:  26%|â–ˆâ–ˆâ–Œ       | 711/2714 [00:02<00:06, 293.43batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  27%|â–ˆâ–ˆâ–‹       | 741/2714 [00:02<00:06, 286.93batch/s]\u001b[A\nEpoch 7/10:  28%|â–ˆâ–ˆâ–Š       | 771/2714 [00:02<00:06, 290.59batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17000] Loss: 1.2058\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  30%|â–ˆâ–ˆâ–‰       | 801/2714 [00:02<00:06, 290.38batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [00:59<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  31%|â–ˆâ–ˆâ–ˆ       | 831/2714 [00:02<00:06, 286.49batch/s]\u001b[A\nEpoch 7/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 861/2714 [00:02<00:06, 290.36batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17100] Loss: 0.9776\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 891/2714 [00:03<00:06, 292.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  34%|â–ˆâ–ˆâ–ˆâ–      | 921/2714 [00:03<00:06, 283.46batch/s]\u001b[A\nEpoch 7/10:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 951/2714 [00:03<00:06, 286.77batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17200] Loss: 0.5524\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 980/2714 [00:03<00:06, 282.47batch/s]\u001b[A\nEpoch 7/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1009/2714 [00:03<00:06, 275.52batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:00<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1037/2714 [00:03<00:06, 275.78batch/s]\u001b[A\nEpoch 7/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1068/2714 [00:03<00:05, 283.39batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17300] Loss: 1.2847\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1097/2714 [00:03<00:05, 285.11batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:01<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1126/2714 [00:03<00:05, 282.72batch/s]\u001b[A\nEpoch 7/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1156/2714 [00:04<00:05, 286.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17400] Loss: 0.8799\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1186/2714 [00:04<00:05, 287.37batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:01<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1216/2714 [00:04<00:05, 286.05batch/s]\u001b[A\nEpoch 7/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1246/2714 [00:04<00:05, 288.44batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17500] Loss: 0.8746\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1276/2714 [00:04<00:04, 290.87batch/s]\u001b[A\nEpoch 7/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1306/2714 [00:04<00:04, 293.10batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:01<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1336/2714 [00:04<00:04, 287.60batch/s]\u001b[A\nEpoch 7/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1366/2714 [00:04<00:04, 289.13batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17600] Loss: 1.0442\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1396/2714 [00:04<00:04, 290.43batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:02<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1426/2714 [00:04<00:04, 287.73batch/s]\u001b[A\nEpoch 7/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1456/2714 [00:05<00:04, 290.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17700] Loss: 1.1329\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1486/2714 [00:05<00:04, 291.77batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:02<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1516/2714 [00:05<00:04, 286.68batch/s]\u001b[A\nEpoch 7/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1545/2714 [00:05<00:04, 287.49batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17800] Loss: 0.9238\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1575/2714 [00:05<00:03, 289.01batch/s]\u001b[A\nEpoch 7/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1605/2714 [00:05<00:03, 290.31batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:02<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1635/2714 [00:05<00:03, 285.21batch/s]\u001b[A\nEpoch 7/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1665/2714 [00:05<00:03, 287.58batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 17900] Loss: 1.5013\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1695/2714 [00:05<00:03, 288.94batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:03<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1724/2714 [00:06<00:03, 284.15batch/s]\u001b[A\nEpoch 7/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1753/2714 [00:06<00:03, 285.28batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18000] Loss: 1.2240\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1782/2714 [00:06<00:03, 286.57batch/s]\u001b[A\nEpoch 7/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1812/2714 [00:06<00:03, 289.10batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:03<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1841/2714 [00:06<00:03, 283.92batch/s]\u001b[A\nEpoch 7/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1871/2714 [00:06<00:02, 286.28batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18100] Loss: 1.5351\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1900/2714 [00:06<00:02, 287.03batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:03<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1929/2714 [00:06<00:02, 282.96batch/s]\u001b[A\nEpoch 7/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1959/2714 [00:06<00:02, 287.26batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18200] Loss: 1.0103\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1989/2714 [00:06<00:02, 289.19batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:04<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2018/2714 [00:07<00:02, 284.25batch/s]\u001b[A\nEpoch 7/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2048/2714 [00:07<00:02, 287.55batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18300] Loss: 1.4778\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2078/2714 [00:07<00:02, 289.62batch/s]\u001b[A\nEpoch 7/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2108/2714 [00:07<00:02, 290.50batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:04<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2138/2714 [00:07<00:02, 286.08batch/s]\u001b[A\nEpoch 7/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2168/2714 [00:07<00:01, 289.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18400] Loss: 0.6039\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2197/2714 [00:07<00:01, 286.03batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:04<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2226/2714 [00:07<00:01, 282.38batch/s]\u001b[A\nEpoch 7/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2255/2714 [00:07<00:01, 283.76batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18500] Loss: 1.0064\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2285/2714 [00:07<00:01, 286.73batch/s]\u001b[A\nEpoch 7/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2315/2714 [00:08<00:01, 290.06batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:05<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2345/2714 [00:08<00:01, 284.29batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18600] Loss: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2374/2714 [00:08<00:01, 284.52batch/s]\u001b[A\nEpoch 7/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2404/2714 [00:08<00:01, 286.20batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:05<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2433/2714 [00:08<00:00, 282.29batch/s]\u001b[A\nEpoch 7/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2463/2714 [00:08<00:00, 286.58batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18700] Loss: 0.6451\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2493/2714 [00:08<00:00, 288.02batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:05<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2522/2714 [00:08<00:00, 284.22batch/s]\u001b[A\nEpoch 7/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2551/2714 [00:08<00:00, 285.68batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18800] Loss: 1.2561\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2580/2714 [00:09<00:00, 285.67batch/s]\u001b[A\nEpoch 7/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2609/2714 [00:09<00:00, 286.63batch/s]\u001b[A\n                                                                                     \nTraining Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [01:06<00:38,  9.53s/epoch, avg_loss=1.1545]\nEpoch 7/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2638/2714 [00:09<00:00, 283.30batch/s]\u001b[A\nEpoch 7/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2668/2714 [00:09<00:00, 286.87batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 18900] Loss: 1.1450\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 7/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2697/2714 [00:09<00:00, 286.81batch/s]\u001b[A\nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:06<00:28,  9.51s/epoch, avg_loss=1.1043]","output_type":"stream"},{"name":"stdout","text":"Epoch 7/10 completed | Avg Loss: 1.1043\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:06<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:   1%|          | 28/2714 [00:00<00:09, 275.45batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19000] Loss: 0.9009\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:   2%|â–         | 57/2714 [00:00<00:09, 279.80batch/s]\u001b[A\nEpoch 8/10:   3%|â–Ž         | 86/2714 [00:00<00:09, 283.88batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:06<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:   4%|â–         | 115/2714 [00:00<00:09, 278.97batch/s]\u001b[A\nEpoch 8/10:   5%|â–Œ         | 145/2714 [00:00<00:08, 286.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19100] Loss: 0.9490\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:   6%|â–‹         | 175/2714 [00:00<00:08, 288.66batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:07<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:   8%|â–Š         | 204/2714 [00:00<00:08, 284.56batch/s]\u001b[A\nEpoch 8/10:   9%|â–Š         | 234/2714 [00:00<00:08, 288.08batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19200] Loss: 0.8528\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  10%|â–‰         | 264/2714 [00:00<00:08, 290.08batch/s]\u001b[A\nEpoch 8/10:  11%|â–ˆ         | 294/2714 [00:01<00:08, 292.35batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:07<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  12%|â–ˆâ–        | 324/2714 [00:01<00:08, 286.66batch/s]\u001b[A\nEpoch 8/10:  13%|â–ˆâ–Ž        | 354/2714 [00:01<00:08, 289.59batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19300] Loss: 0.5180\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  14%|â–ˆâ–        | 383/2714 [00:01<00:08, 288.98batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:07<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  15%|â–ˆâ–Œ        | 412/2714 [00:01<00:08, 281.33batch/s]\u001b[A\nEpoch 8/10:  16%|â–ˆâ–‹        | 442/2714 [00:01<00:07, 284.10batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19400] Loss: 0.9761\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  17%|â–ˆâ–‹        | 471/2714 [00:01<00:07, 285.30batch/s]\u001b[A\nEpoch 8/10:  18%|â–ˆâ–Š        | 501/2714 [00:01<00:07, 288.26batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:08<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  20%|â–ˆâ–‰        | 530/2714 [00:01<00:07, 284.76batch/s]\u001b[A\nEpoch 8/10:  21%|â–ˆâ–ˆ        | 560/2714 [00:01<00:07, 286.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19500] Loss: 1.2167\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  22%|â–ˆâ–ˆâ–       | 589/2714 [00:02<00:07, 287.22batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:08<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  23%|â–ˆâ–ˆâ–Ž       | 618/2714 [00:02<00:07, 284.24batch/s]\u001b[A\nEpoch 8/10:  24%|â–ˆâ–ˆâ–       | 648/2714 [00:02<00:07, 288.84batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19600] Loss: 0.7476\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  25%|â–ˆâ–ˆâ–       | 677/2714 [00:02<00:07, 287.06batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:09<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  26%|â–ˆâ–ˆâ–Œ       | 706/2714 [00:02<00:07, 284.41batch/s]\u001b[A\nEpoch 8/10:  27%|â–ˆâ–ˆâ–‹       | 736/2714 [00:02<00:06, 288.04batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19700] Loss: 1.3438\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  28%|â–ˆâ–ˆâ–Š       | 766/2714 [00:02<00:06, 289.13batch/s]\u001b[A\nEpoch 8/10:  29%|â–ˆâ–ˆâ–‰       | 796/2714 [00:02<00:06, 290.52batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:09<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  30%|â–ˆâ–ˆâ–ˆ       | 826/2714 [00:02<00:06, 286.40batch/s]\u001b[A\nEpoch 8/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 856/2714 [00:02<00:06, 287.78batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19800] Loss: 0.8587\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 886/2714 [00:03<00:06, 290.14batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:09<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  34%|â–ˆâ–ˆâ–ˆâ–      | 916/2714 [00:03<00:06, 286.29batch/s]\u001b[A\nEpoch 8/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 946/2714 [00:03<00:06, 289.60batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 19900] Loss: 1.2168\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 975/2714 [00:03<00:06, 288.97batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1004/2714 [00:03<00:06, 284.12batch/s]\u001b[A\nEpoch 8/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1034/2714 [00:03<00:05, 286.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20000] Loss: 0.8852\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1063/2714 [00:03<00:05, 278.22batch/s]\u001b[A\nEpoch 8/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1093/2714 [00:03<00:05, 283.46batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1122/2714 [00:03<00:05, 275.32batch/s]\u001b[A\nEpoch 8/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1150/2714 [00:04<00:05, 267.52batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20100] Loss: 0.8031\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1180/2714 [00:04<00:05, 275.16batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:10<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1208/2714 [00:04<00:05, 275.13batch/s]\u001b[A\nEpoch 8/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1238/2714 [00:04<00:05, 281.32batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20200] Loss: 0.9588\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1268/2714 [00:04<00:05, 285.59batch/s]\u001b[A\nEpoch 8/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1298/2714 [00:04<00:04, 287.58batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:11<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1327/2714 [00:04<00:04, 283.21batch/s]\u001b[A\nEpoch 8/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1356/2714 [00:04<00:04, 285.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20300] Loss: 0.7040\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1386/2714 [00:04<00:04, 287.01batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:11<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1415/2714 [00:04<00:04, 283.04batch/s]\u001b[A\nEpoch 8/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1446/2714 [00:05<00:04, 288.30batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20400] Loss: 1.0402\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1476/2714 [00:05<00:04, 289.83batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:11<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1505/2714 [00:05<00:04, 285.08batch/s]\u001b[A\nEpoch 8/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1535/2714 [00:05<00:04, 288.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20500] Loss: 1.1648\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1565/2714 [00:05<00:03, 289.15batch/s]\u001b[A\nEpoch 8/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1595/2714 [00:05<00:03, 292.07batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1625/2714 [00:05<00:03, 285.87batch/s]\u001b[A\nEpoch 8/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1655/2714 [00:05<00:03, 287.69batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20600] Loss: 1.0869\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1684/2714 [00:05<00:03, 287.52batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1713/2714 [00:06<00:03, 283.51batch/s]\u001b[A\nEpoch 8/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1742/2714 [00:06<00:03, 281.60batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20700] Loss: 1.5991\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1772/2714 [00:06<00:03, 284.31batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:12<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1802/2714 [00:06<00:03, 282.28batch/s]\u001b[A\nEpoch 8/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1831/2714 [00:06<00:03, 282.80batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20800] Loss: 0.8049\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1861/2714 [00:06<00:02, 285.69batch/s]\u001b[A\nEpoch 8/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1891/2714 [00:06<00:02, 287.29batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:13<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1920/2714 [00:06<00:02, 282.76batch/s]\u001b[A\nEpoch 8/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1950/2714 [00:06<00:02, 285.73batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 20900] Loss: 0.8777\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1980/2714 [00:06<00:02, 287.60batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:13<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2009/2714 [00:07<00:02, 283.13batch/s]\u001b[A\nEpoch 8/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2039/2714 [00:07<00:02, 286.07batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21000] Loss: 1.2365\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2068/2714 [00:07<00:02, 286.08batch/s]\u001b[A\nEpoch 8/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2098/2714 [00:07<00:02, 288.33batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:13<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2127/2714 [00:07<00:02, 283.53batch/s]\u001b[A\nEpoch 8/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2157/2714 [00:07<00:01, 287.14batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21100] Loss: 1.1129\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2187/2714 [00:07<00:01, 288.93batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:14<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2216/2714 [00:07<00:01, 283.33batch/s]\u001b[A\nEpoch 8/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2246/2714 [00:07<00:01, 287.98batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21200] Loss: 1.1653\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2276/2714 [00:07<00:01, 290.23batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:14<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2306/2714 [00:08<00:01, 286.36batch/s]\u001b[A\nEpoch 8/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2336/2714 [00:08<00:01, 289.94batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21300] Loss: 1.1835\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2366/2714 [00:08<00:01, 289.72batch/s]\u001b[A\nEpoch 8/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2396/2714 [00:08<00:01, 291.50batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:14<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2426/2714 [00:08<00:01, 286.68batch/s]\u001b[A\nEpoch 8/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2456/2714 [00:08<00:00, 288.95batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21400] Loss: 1.6513\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2485/2714 [00:08<00:00, 287.57batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:15<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2514/2714 [00:08<00:00, 283.11batch/s]\u001b[A\nEpoch 8/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2544/2714 [00:08<00:00, 285.65batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21500] Loss: 0.9542\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2574/2714 [00:09<00:00, 287.56batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:15<00:28,  9.51s/epoch, avg_loss=1.1043]\nEpoch 8/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2603/2714 [00:09<00:00, 281.76batch/s]\u001b[A\nEpoch 8/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2633/2714 [00:09<00:00, 286.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21600] Loss: 1.7032\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 8/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2662/2714 [00:09<00:00, 287.06batch/s]\u001b[A\nEpoch 8/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2691/2714 [00:09<00:00, 287.29batch/s]\u001b[A\n                                                                                     \nTraining Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [01:16<00:28,  9.51s/epoch, avg_loss=1.1043]\nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:16<00:19,  9.51s/epoch, avg_loss=1.0491]","output_type":"stream"},{"name":"stdout","text":"[Step 21700] Loss: 1.5198\nEpoch 8/10 completed | Avg Loss: 1.0491\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 9/10:   1%|          | 30/2714 [00:00<00:08, 299.21batch/s]\u001b[A\nEpoch 9/10:   2%|â–         | 60/2714 [00:00<00:09, 292.25batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:16<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:   3%|â–Ž         | 90/2714 [00:00<00:09, 284.06batch/s]\u001b[A\nEpoch 9/10:   4%|â–         | 119/2714 [00:00<00:09, 285.80batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21800] Loss: 1.3567\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:   5%|â–Œ         | 148/2714 [00:00<00:08, 287.09batch/s]\u001b[A\nEpoch 9/10:   7%|â–‹         | 178/2714 [00:00<00:08, 290.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:16<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:   8%|â–Š         | 208/2714 [00:00<00:08, 284.28batch/s]\u001b[A\nEpoch 9/10:   9%|â–‰         | 238/2714 [00:00<00:08, 286.85batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 21900] Loss: 0.9062\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  10%|â–‰         | 268/2714 [00:00<00:08, 288.55batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  11%|â–ˆ         | 297/2714 [00:01<00:08, 282.76batch/s]\u001b[A\nEpoch 9/10:  12%|â–ˆâ–        | 327/2714 [00:01<00:08, 285.51batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22000] Loss: 0.9105\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  13%|â–ˆâ–Ž        | 357/2714 [00:01<00:08, 287.13batch/s]\u001b[A\nEpoch 9/10:  14%|â–ˆâ–        | 387/2714 [00:01<00:08, 288.91batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  15%|â–ˆâ–Œ        | 416/2714 [00:01<00:08, 285.19batch/s]\u001b[A\nEpoch 9/10:  16%|â–ˆâ–‹        | 446/2714 [00:01<00:07, 287.32batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22100] Loss: 0.8386\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  18%|â–ˆâ–Š        | 475/2714 [00:01<00:07, 288.07batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:17<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  19%|â–ˆâ–Š        | 504/2714 [00:01<00:07, 283.80batch/s]\u001b[A\nEpoch 9/10:  20%|â–ˆâ–‰        | 533/2714 [00:01<00:07, 284.51batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22200] Loss: 0.9626\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  21%|â–ˆâ–ˆ        | 562/2714 [00:01<00:07, 282.62batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  22%|â–ˆâ–ˆâ–       | 591/2714 [00:02<00:07, 275.50batch/s]\u001b[A\nEpoch 9/10:  23%|â–ˆâ–ˆâ–Ž       | 621/2714 [00:02<00:07, 281.89batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22300] Loss: 0.8364\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  24%|â–ˆâ–ˆâ–       | 651/2714 [00:02<00:07, 284.69batch/s]\u001b[A\nEpoch 9/10:  25%|â–ˆâ–ˆâ–Œ       | 681/2714 [00:02<00:07, 286.50batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  26%|â–ˆâ–ˆâ–Œ       | 710/2714 [00:02<00:07, 282.09batch/s]\u001b[A\nEpoch 9/10:  27%|â–ˆâ–ˆâ–‹       | 740/2714 [00:02<00:06, 287.19batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22400] Loss: 1.7684\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  28%|â–ˆâ–ˆâ–Š       | 770/2714 [00:02<00:06, 289.92batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:18<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  29%|â–ˆâ–ˆâ–‰       | 800/2714 [00:02<00:06, 286.28batch/s]\u001b[A\nEpoch 9/10:  31%|â–ˆâ–ˆâ–ˆ       | 829/2714 [00:02<00:06, 286.00batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22500] Loss: 0.9664\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 859/2714 [00:03<00:06, 289.52batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:19<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 888/2714 [00:03<00:06, 288.16batch/s]\u001b[A\nEpoch 9/10:  34%|â–ˆâ–ˆâ–ˆâ–      | 918/2714 [00:03<00:06, 290.92batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22600] Loss: 1.2770\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 948/2714 [00:03<00:06, 292.56batch/s]\u001b[A\nEpoch 9/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 978/2714 [00:03<00:05, 292.72batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:19<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 1008/2714 [00:03<00:06, 283.49batch/s]\u001b[A\nEpoch 9/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1038/2714 [00:03<00:05, 287.50batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22700] Loss: 1.2547\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1067/2714 [00:03<00:05, 287.61batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:19<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1096/2714 [00:03<00:05, 282.43batch/s]\u001b[A\nEpoch 9/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1125/2714 [00:03<00:05, 283.80batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22800] Loss: 1.3360\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1155/2714 [00:04<00:05, 285.93batch/s]\u001b[A\nEpoch 9/10:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1184/2714 [00:04<00:05, 284.45batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:20<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1213/2714 [00:04<00:05, 280.18batch/s]\u001b[A\nEpoch 9/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1243/2714 [00:04<00:05, 283.42batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 22900] Loss: 0.8018\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1272/2714 [00:04<00:05, 271.69batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:20<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1300/2714 [00:04<00:05, 269.10batch/s]\u001b[A\nEpoch 9/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1330/2714 [00:04<00:05, 275.82batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23000] Loss: 1.3041\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1360/2714 [00:04<00:04, 280.75batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:20<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1389/2714 [00:04<00:04, 276.27batch/s]\u001b[A\nEpoch 9/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1419/2714 [00:04<00:04, 281.68batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23100] Loss: 0.7101\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1449/2714 [00:05<00:04, 285.47batch/s]\u001b[A\nEpoch 9/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1479/2714 [00:05<00:04, 288.49batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:21<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1508/2714 [00:05<00:04, 284.57batch/s]\u001b[A\nEpoch 9/10:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1538/2714 [00:05<00:04, 288.01batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23200] Loss: 0.7750\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1568/2714 [00:05<00:03, 289.41batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:21<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1597/2714 [00:05<00:03, 286.55batch/s]\u001b[A\nEpoch 9/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1626/2714 [00:05<00:03, 287.03batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23300] Loss: 0.7114\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1655/2714 [00:05<00:03, 285.09batch/s]\u001b[A\nEpoch 9/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1685/2714 [00:05<00:03, 287.46batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:22<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1714/2714 [00:06<00:03, 283.93batch/s]\u001b[A\nEpoch 9/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1744/2714 [00:06<00:03, 286.54batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23400] Loss: 0.8625\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1774/2714 [00:06<00:03, 288.98batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:22<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1803/2714 [00:06<00:03, 284.71batch/s]\u001b[A\nEpoch 9/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1833/2714 [00:06<00:03, 289.17batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23500] Loss: 1.3103\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1863/2714 [00:06<00:02, 290.31batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:22<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1893/2714 [00:06<00:02, 276.67batch/s]\u001b[A\nEpoch 9/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1923/2714 [00:06<00:02, 280.90batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23600] Loss: 1.1835\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1952/2714 [00:06<00:02, 279.82batch/s]\u001b[A\nEpoch 9/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1982/2714 [00:06<00:02, 283.20batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:23<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2011/2714 [00:07<00:02, 279.93batch/s]\u001b[A\nEpoch 9/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2041/2714 [00:07<00:02, 283.93batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23700] Loss: 1.1430\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2071/2714 [00:07<00:02, 286.89batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:23<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2100/2714 [00:07<00:02, 282.25batch/s]\u001b[A\nEpoch 9/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2130/2714 [00:07<00:02, 285.55batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23800] Loss: 1.1584\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2160/2714 [00:07<00:01, 287.73batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:23<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2189/2714 [00:07<00:01, 283.29batch/s]\u001b[A\nEpoch 9/10:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2219/2714 [00:07<00:01, 286.50batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 23900] Loss: 1.0502\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2248/2714 [00:07<00:01, 286.31batch/s]\u001b[A\nEpoch 9/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2278/2714 [00:07<00:01, 288.01batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:24<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2307/2714 [00:08<00:01, 283.14batch/s]\u001b[A\nEpoch 9/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2337/2714 [00:08<00:01, 285.51batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24000] Loss: 0.6630\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2366/2714 [00:08<00:01, 286.36batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:24<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2395/2714 [00:08<00:01, 281.79batch/s]\u001b[A\nEpoch 9/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2424/2714 [00:08<00:01, 283.98batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24100] Loss: 0.8171\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2454/2714 [00:08<00:00, 285.87batch/s]\u001b[A\nEpoch 9/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2484/2714 [00:08<00:00, 289.45batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:24<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2513/2714 [00:08<00:00, 284.41batch/s]\u001b[A\nEpoch 9/10:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2543/2714 [00:08<00:00, 286.38batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24200] Loss: 0.6836\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2573/2714 [00:09<00:00, 288.53batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:25<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2602/2714 [00:09<00:00, 284.78batch/s]\u001b[A\nEpoch 9/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2633/2714 [00:09<00:00, 289.78batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24300] Loss: 1.3070\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 9/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2663/2714 [00:09<00:00, 290.61batch/s]\u001b[A\n                                                                                     \nTraining Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [01:25<00:19,  9.51s/epoch, avg_loss=1.0491]\nEpoch 9/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2693/2714 [00:09<00:00, 285.55batch/s]\u001b[A\nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:25<00:09,  9.52s/epoch, avg_loss=0.9979]","output_type":"stream"},{"name":"stdout","text":"[Step 24400] Loss: 0.8672\nEpoch 9/10 completed | Avg Loss: 0.9979\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:   0%|          | 0/2714 [00:00<?, ?batch/s]\u001b[A\nEpoch 10/10:   1%|          | 29/2714 [00:00<00:09, 288.08batch/s]\u001b[A\nEpoch 10/10:   2%|â–         | 58/2714 [00:00<00:09, 286.19batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:25<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:   3%|â–Ž         | 87/2714 [00:00<00:09, 278.80batch/s]\u001b[A\nEpoch 10/10:   4%|â–         | 117/2714 [00:00<00:09, 283.77batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24500] Loss: 1.1448\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:   5%|â–Œ         | 146/2714 [00:00<00:08, 285.53batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:26<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:   6%|â–‹         | 175/2714 [00:00<00:09, 280.10batch/s]\u001b[A\nEpoch 10/10:   8%|â–Š         | 205/2714 [00:00<00:08, 283.73batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24600] Loss: 0.6320\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:   9%|â–Š         | 234/2714 [00:00<00:08, 285.06batch/s]\u001b[A\nEpoch 10/10:  10%|â–‰         | 264/2714 [00:00<00:08, 287.39batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:26<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  11%|â–ˆ         | 293/2714 [00:01<00:08, 281.31batch/s]\u001b[A\nEpoch 10/10:  12%|â–ˆâ–        | 322/2714 [00:01<00:08, 283.69batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24700] Loss: 1.0472\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  13%|â–ˆâ–Ž        | 351/2714 [00:01<00:08, 285.40batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:26<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  14%|â–ˆâ–        | 380/2714 [00:01<00:08, 280.42batch/s]\u001b[A\nEpoch 10/10:  15%|â–ˆâ–Œ        | 410/2714 [00:01<00:08, 286.17batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24800] Loss: 0.5829\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  16%|â–ˆâ–Œ        | 439/2714 [00:01<00:07, 287.27batch/s]\u001b[A\nEpoch 10/10:  17%|â–ˆâ–‹        | 468/2714 [00:01<00:07, 287.52batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:27<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  18%|â–ˆâ–Š        | 497/2714 [00:01<00:07, 281.36batch/s]\u001b[A\nEpoch 10/10:  19%|â–ˆâ–‰        | 527/2714 [00:01<00:07, 285.28batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 24900] Loss: 1.2479\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  20%|â–ˆâ–ˆ        | 556/2714 [00:01<00:07, 286.31batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:27<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  22%|â–ˆâ–ˆâ–       | 585/2714 [00:02<00:07, 281.81batch/s]\u001b[A\nEpoch 10/10:  23%|â–ˆâ–ˆâ–Ž       | 614/2714 [00:02<00:07, 283.47batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25000] Loss: 0.8162\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  24%|â–ˆâ–ˆâ–Ž       | 643/2714 [00:02<00:07, 285.35batch/s]\u001b[A\nEpoch 10/10:  25%|â–ˆâ–ˆâ–       | 673/2714 [00:02<00:07, 287.19batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:28<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  26%|â–ˆâ–ˆâ–Œ       | 702/2714 [00:02<00:07, 282.86batch/s]\u001b[A\nEpoch 10/10:  27%|â–ˆâ–ˆâ–‹       | 732/2714 [00:02<00:06, 285.52batch/s]","output_type":"stream"},{"name":"stdout","text":"[Step 25100] Loss: 0.8429\n","output_type":"stream"},{"name":"stderr","text":"\u001b[A\nEpoch 10/10:  28%|â–ˆâ–ˆâ–Š       | 762/2714 [00:02<00:06, 287.70batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:28<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  29%|â–ˆâ–ˆâ–‰       | 791/2714 [00:02<00:06, 283.61batch/s]\u001b[A\nEpoch 10/10:  30%|â–ˆâ–ˆâ–ˆ       | 820/2714 [00:02<00:06, 282.12batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25200] Loss: 0.9429\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  31%|â–ˆâ–ˆâ–ˆâ–      | 849/2714 [00:02<00:06, 284.28batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:28<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  32%|â–ˆâ–ˆâ–ˆâ–      | 878/2714 [00:03<00:06, 280.53batch/s]\u001b[A\nEpoch 10/10:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 908/2714 [00:03<00:06, 284.35batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25300] Loss: 0.8792\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  35%|â–ˆâ–ˆâ–ˆâ–      | 938/2714 [00:03<00:06, 287.85batch/s]\u001b[A\nEpoch 10/10:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 968/2714 [00:03<00:06, 289.69batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 997/2714 [00:03<00:05, 286.43batch/s]\u001b[A\nEpoch 10/10:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 1027/2714 [00:03<00:05, 289.70batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25400] Loss: 1.0824\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 1057/2714 [00:03<00:05, 290.10batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1087/2714 [00:03<00:05, 286.92batch/s]\u001b[A\nEpoch 10/10:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 1117/2714 [00:03<00:05, 289.44batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25500] Loss: 1.5025\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1147/2714 [00:04<00:05, 290.59batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:29<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 1177/2714 [00:04<00:05, 287.40batch/s]\u001b[A\nEpoch 10/10:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 1208/2714 [00:04<00:05, 291.23batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25600] Loss: 1.0657\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1238/2714 [00:04<00:05, 292.22batch/s]\u001b[A\nEpoch 10/10:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 1268/2714 [00:04<00:04, 292.89batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 1298/2714 [00:04<00:04, 287.63batch/s]\u001b[A\nEpoch 10/10:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1327/2714 [00:04<00:04, 287.25batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25700] Loss: 0.7918\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 1356/2714 [00:04<00:04, 287.99batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1385/2714 [00:04<00:04, 283.79batch/s]\u001b[A\nEpoch 10/10:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1414/2714 [00:04<00:04, 266.77batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25800] Loss: 1.2600\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 1444/2714 [00:05<00:04, 274.68batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:30<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 1474/2714 [00:05<00:04, 276.53batch/s]\u001b[A\nEpoch 10/10:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 1503/2714 [00:05<00:04, 280.35batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 25900] Loss: 0.6657\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 1533/2714 [00:05<00:04, 283.68batch/s]\u001b[A\nEpoch 10/10:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1563/2714 [00:05<00:04, 287.26batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:31<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 1592/2714 [00:05<00:03, 283.68batch/s]\u001b[A\nEpoch 10/10:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 1622/2714 [00:05<00:03, 287.72batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26000] Loss: 0.9357\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 1651/2714 [00:05<00:03, 288.32batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:31<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1680/2714 [00:05<00:03, 283.99batch/s]\u001b[A\nEpoch 10/10:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 1710/2714 [00:05<00:03, 287.48batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26100] Loss: 0.6660\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 1739/2714 [00:06<00:03, 287.70batch/s]\u001b[A\nEpoch 10/10:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 1769/2714 [00:06<00:03, 290.55batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:31<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1799/2714 [00:06<00:03, 286.85batch/s]\u001b[A\nEpoch 10/10:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 1828/2714 [00:06<00:03, 287.40batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26200] Loss: 0.8165\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 1857/2714 [00:06<00:02, 286.51batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:32<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 1886/2714 [00:06<00:02, 281.54batch/s]\u001b[A\nEpoch 10/10:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 1915/2714 [00:06<00:02, 284.00batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26300] Loss: 1.1779\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 1944/2714 [00:06<00:02, 284.90batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:32<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 1974/2714 [00:06<00:02, 281.81batch/s]\u001b[A\nEpoch 10/10:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2004/2714 [00:07<00:02, 285.96batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26400] Loss: 0.7511\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 2034/2714 [00:07<00:02, 288.85batch/s]\u001b[A\nEpoch 10/10:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 2064/2714 [00:07<00:02, 289.39batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:32<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 2093/2714 [00:07<00:02, 283.83batch/s]\u001b[A\nEpoch 10/10:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 2122/2714 [00:07<00:02, 284.89batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26500] Loss: 0.9532\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 2152/2714 [00:07<00:01, 286.75batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:33<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 2181/2714 [00:07<00:01, 282.47batch/s]\u001b[A\nEpoch 10/10:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2211/2714 [00:07<00:01, 285.96batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26600] Loss: 1.1972\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2241/2714 [00:07<00:01, 287.30batch/s]\u001b[A\nEpoch 10/10:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 2271/2714 [00:07<00:01, 289.12batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:33<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 2300/2714 [00:08<00:01, 284.78batch/s]\u001b[A\nEpoch 10/10:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 2330/2714 [00:08<00:01, 286.78batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26700] Loss: 1.0324\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 2359/2714 [00:08<00:01, 287.38batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:33<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 2388/2714 [00:08<00:01, 283.90batch/s]\u001b[A\nEpoch 10/10:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 2418/2714 [00:08<00:01, 287.29batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26800] Loss: 1.3292\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 2448/2714 [00:08<00:00, 289.77batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:34<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2477/2714 [00:08<00:00, 286.57batch/s]\u001b[A\nEpoch 10/10:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2507/2714 [00:08<00:00, 288.27batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 26900] Loss: 0.9535\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 2537/2714 [00:08<00:00, 289.54batch/s]\u001b[A\nEpoch 10/10:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 2567/2714 [00:08<00:00, 290.92batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:34<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 2597/2714 [00:09<00:00, 287.04batch/s]\u001b[A\nEpoch 10/10:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 2627/2714 [00:09<00:00, 288.79batch/s]\u001b[A","output_type":"stream"},{"name":"stdout","text":"[Step 27000] Loss: 0.4509\n","output_type":"stream"},{"name":"stderr","text":"\nEpoch 10/10:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 2657/2714 [00:09<00:00, 290.03batch/s]\u001b[A\n                                                                                     \nTraining Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [01:34<00:09,  9.52s/epoch, avg_loss=0.9979]\nEpoch 10/10:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 2687/2714 [00:09<00:00, 284.16batch/s]\u001b[A\nTraining Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [01:35<00:00,  9.51s/epoch, avg_loss=0.9436]","output_type":"stream"},{"name":"stdout","text":"[Step 27100] Loss: 1.0629\nEpoch 10/10 completed | Avg Loss: 0.9436\n\nâœ“ Training completed!\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"# 9. Evaluation\ndef evaluate_emotion_head(model, head, dataloader):\n    head.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for batch in dataloader:\n            features = get_pooled_features(\n                model,\n                batch[\"input_ids\"],\n                batch[\"attention_mask\"]\n            )\n            logits = head(features)\n            preds = logits.argmax(dim=-1)\n\n            correct += (preds == batch[\"labels\"]).sum().item()\n            total += batch[\"labels\"].size(0)\n\n    acc = correct / total\n    print(f\"Emotion classification accuracy: {acc:.4f} ({correct}/{total})\")\n    head.train()\n    \n    return acc\n\nprint(\"=\"*60)\nprint(\"EVALUATION\")\nprint(\"=\"*60)\naccuracy = evaluate_emotion_head(model, emotion_head, emotion_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:50:03.843716Z","iopub.execute_input":"2026-01-21T14:50:03.843970Z","iopub.status.idle":"2026-01-21T14:50:08.725898Z","shell.execute_reply.started":"2026-01-21T14:50:03.843942Z","shell.execute_reply":"2026-01-21T14:50:08.725094Z"}},"outputs":[{"name":"stdout","text":"============================================================\nEVALUATION\n============================================================\nEmotion classification accuracy: 0.7556 (32799/43410)\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"# 10. Save\ntorch.save({\n    'emotion_head_state_dict': emotion_head.state_dict(),\n    'hidden_dim': hidden_dim,\n    'num_labels': 28,\n}, \"emotion_head.pt\")\n\nprint(\"\\nâœ“ Emotion head saved to emotion_head.pt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:50:08.726928Z","iopub.execute_input":"2026-01-21T14:50:08.727334Z","iopub.status.idle":"2026-01-21T14:50:08.753632Z","shell.execute_reply.started":"2026-01-21T14:50:08.727284Z","shell.execute_reply":"2026-01-21T14:50:08.753014Z"}},"outputs":[{"name":"stdout","text":"\nâœ“ Emotion head saved to emotion_head.pt\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import os\nimport json\nimport torch\n\nSAVE_DIR = \"emotion_head\"\n\nos.makedirs(SAVE_DIR, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:52:33.597765Z","iopub.execute_input":"2026-01-21T14:52:33.598707Z","iopub.status.idle":"2026-01-21T14:52:33.602760Z","shell.execute_reply.started":"2026-01-21T14:52:33.598668Z","shell.execute_reply":"2026-01-21T14:52:33.601967Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"torch.save(\n    emotion_head.state_dict(),\n    f\"{SAVE_DIR}/emotion_head.pt\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:53:31.813583Z","iopub.execute_input":"2026-01-21T14:53:31.814063Z","iopub.status.idle":"2026-01-21T14:53:31.828322Z","shell.execute_reply.started":"2026-01-21T14:53:31.814029Z","shell.execute_reply":"2026-01-21T14:53:31.827419Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"GOEMOTIONS_LABELS = [\n    \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\",\n    \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\",\n    \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\",\n    \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\",\n    \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\"\n]\n\nconfig = {\n    \"head_type\": \"emotion\",\n    \"dataset\": \"go_emotions\",\n    \"num_labels\": 28,\n    \"bottleneck_dim\": 512,\n    \"label_map\": {i: lbl for i, lbl in enumerate(GOEMOTIONS_LABELS)},\n    \"pooling\": \"final_token_logits\",\n    \"logits_to_keep\": 1,\n    \"precision\": \"fp32_head_fp16_backbone\"\n}\n\nwith open(f\"{SAVE_DIR}/config.json\", \"w\") as f:\n    json.dump(config, f, indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:53:45.552771Z","iopub.execute_input":"2026-01-21T14:53:45.553101Z","iopub.status.idle":"2026-01-21T14:53:45.559086Z","shell.execute_reply.started":"2026-01-21T14:53:45.553069Z","shell.execute_reply":"2026-01-21T14:53:45.558306Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"readme = f\"\"\"\n# Emotion Classification Head (GoEmotions)\n\nThis repository contains an **auxiliary emotion classification head**\ntrained on **GoEmotions**, designed to be used with a frozen\nMixture-of-Experts causal language model backbone.\n\n## Architecture\n- Input: final-token logits from backbone (`logits_to_keep=1`)\n- Bottleneck projection: {config[\"bottleneck_dim\"]} dimensions\n- Classifier: LayerNorm â†’ Linear (28 labels)\n\n## Training\n- Backbone: frozen\n- Loss: CrossEntropy\n- Precision: fp32 head, fp16 backbone\n- Dataset: GoEmotions\n\n## Labels\n{\", \".join(GOEMOTIONS_LABELS)}\n\n## Usage\nLoad `emotion_head.pt` and `logit_bottleneck.pt` and attach to a compatible backbone.\n\"\"\"\n\nwith open(f\"{SAVE_DIR}/README.md\", \"w\") as f:\n    f.write(readme)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:54:02.048636Z","iopub.execute_input":"2026-01-21T14:54:02.049204Z","iopub.status.idle":"2026-01-21T14:54:02.053963Z","shell.execute_reply.started":"2026-01-21T14:54:02.049169Z","shell.execute_reply":"2026-01-21T14:54:02.053231Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"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","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:54:23.939320Z","iopub.execute_input":"2026-01-21T14:54:23.939658Z","iopub.status.idle":"2026-01-21T14:54:23.955509Z","shell.execute_reply.started":"2026-01-21T14:54:23.939626Z","shell.execute_reply":"2026-01-21T14:54:23.954698Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5896e3e4c319442088cfad88eb29ab6f"}},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"from huggingface_hub import HfApi\n\nrepo_id = \"Aharneish/emotion-head-goemotions\"\n\napi = HfApi()\napi.create_repo(\n    repo_id=repo_id,\n    repo_type=\"model\",\n    exist_ok=True\n)\n\napi.upload_folder(\n    folder_path=SAVE_DIR,\n    repo_id=repo_id,\n    repo_type=\"model\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:56:07.286209Z","iopub.execute_input":"2026-01-21T14:56:07.286914Z","iopub.status.idle":"2026-01-21T14:56:10.895571Z","shell.execute_reply.started":"2026-01-21T14:56:07.286878Z","shell.execute_reply":"2026-01-21T14:56:10.894846Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f561139e712c4c7b8149129833ef339d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d66e5b8adc384cff81c8ae10c2afa2be"}},"metadata":{}},{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/Aharneish/emotion-head-goemotions/commit/ca0c3bf2845cd915af11b0435dcb4465ef483ece', commit_message='Upload folder using huggingface_hub', commit_description='', oid='ca0c3bf2845cd915af11b0435dcb4465ef483ece', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Aharneish/emotion-head-goemotions', endpoint='https://huggingface.co', repo_type='model', repo_id='Aharneish/emotion-head-goemotions'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\n\nhf_hub_download(\n    repo_id=repo_id,\n    filename=\"emotion_head.pt\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T14:56:18.982527Z","iopub.execute_input":"2026-01-21T14:56:18.983073Z","iopub.status.idle":"2026-01-21T14:56:19.536679Z","shell.execute_reply.started":"2026-01-21T14:56:18.983043Z","shell.execute_reply":"2026-01-21T14:56:19.536151Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"emotion_head.pt:   0%|          | 0.00/5.98M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f34b850f39454c389e18d3c638bb987a"}},"metadata":{}},{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"'/root/.cache/huggingface/hub/models--Aharneish--emotion-head-goemotions/snapshots/ca0c3bf2845cd915af11b0435dcb4465ef483ece/emotion_head.pt'"},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"# Stategy Head","metadata":{}},{"cell_type":"code","source":"STRATEGY_LABELS = {\n    0: \"Question\",\n    1: \"Reflection of feelings\",\n    2: \"Restatement or Paraphrasing\",\n    3: \"Providing Suggestions\",\n    4: \"Affirmation and Reassurance\",\n    5: \"Information\",\n    6: \"Others\"\n}\nNUM_STRATEGIES = len(STRATEGY_LABELS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:01:01.017860Z","iopub.execute_input":"2026-01-21T15:01:01.018169Z","iopub.status.idle":"2026-01-21T15:01:01.022388Z","shell.execute_reply.started":"2026-01-21T15:01:01.018140Z","shell.execute_reply":"2026-01-21T15:01:01.021541Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass StrategyHead(nn.Module):\n    def __init__(self, hidden_dim, num_labels=NUM_STRATEGIES):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.LayerNorm(hidden_dim),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_dim, 512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, num_labels)\n        )\n\n    def forward(self, x):\n        return self.net(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:01:16.541483Z","iopub.execute_input":"2026-01-21T15:01:16.541772Z","iopub.status.idle":"2026-01-21T15:01:16.546848Z","shell.execute_reply.started":"2026-01-21T15:01:16.541742Z","shell.execute_reply":"2026-01-21T15:01:16.546080Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"hidden_dim = embedding_layer.embedding_dim\n\nstrategy_head = StrategyHead(\n    hidden_dim=hidden_dim,\n    num_labels=NUM_STRATEGIES\n).to(device)\n\noptimizer = torch.optim.AdamW(\n    strategy_head.parameters(),\n    lr=2e-4\n)\n\ncriterion = nn.CrossEntropyLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-21T15:04:33.608773Z","iopub.execute_input":"2026-01-21T15:04:33.609556Z","iopub.status.idle":"2026-01-21T15:04:33.616161Z","shell.execute_reply.started":"2026-01-21T15:04:33.609522Z","shell.execute_reply":"2026-01-21T15:04:33.615145Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3134330485.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhidden_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m strategy_head = StrategyHead(\n\u001b[1;32m      4\u001b[0m     \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_STRATEGIES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'embedding_layer' is not defined"],"ename":"NameError","evalue":"name 'embedding_layer' is not defined","output_type":"error"}],"execution_count":43},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ndef collate_fn_strategy(batch):\n    input_ids = [torch.tensor(x[\"input_ids\"]) for x in batch]\n    labels = torch.tensor([x[\"strategy_label\"] for x in batch])\n\n    input_ids = nn.utils.rnn.pad_sequence(\n        input_ids,\n        batch_first=True,\n        padding_value=tokenizer.pad_token_id\n    )\n\n    attention_mask = (input_ids != tokenizer.pad_token_id).long()\n\n    return {\n        \"input_ids\": input_ids.to(device),\n        \"attention_mask\": attention_mask.to(device),\n        \"labels\": labels.to(device)\n    }\n\nstrategy_loader = DataLoader(\n    dataset2,          # ESConv processed dataset\n    batch_size=16,\n    shuffle=True,\n    collate_fn=collate_fn_strategy\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 3\nlog_every = 100\nstep = 0\n\nstrategy_head.train()\n\nfor epoch in range(num_epochs):\n    total_loss = 0.0\n\n    for batch in strategy_loader:\n        features = get_pooled_features(\n            model,\n            batch[\"input_ids\"],\n            batch[\"attention_mask\"]\n        )\n\n        logits = strategy_head(features)\n        loss = criterion(logits, batch[\"labels\"])\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n        step += 1\n\n        if step % log_every == 0:\n            print(f\"Epoch {epoch} | Step {step} | Loss {loss.item():.4f}\")\n\n    avg_loss = total_loss / len(strategy_loader)\n    print(f\"Epoch {epoch} finished | Avg loss {avg_loss:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def evaluate_strategy_head(model, head, loader):\n    head.eval()\n    correct, total = 0, 0\n\n    with torch.no_grad():\n        for batch in loader:\n            features = get_pooled_features(\n                model,\n                batch[\"input_ids\"],\n                batch[\"attention_mask\"]\n            )\n            preds = head(features).argmax(dim=-1)\n            correct += (preds == batch[\"labels\"]).sum().item()\n            total += batch[\"labels\"].size(0)\n\n    acc = correct / total\n    print(f\"Strategy accuracy: {acc:.4f}\")\n    head.train()\n\nevaluate_strategy_head(model, strategy_head, strategy_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(strategy_head.state_dict(), \"strategy_head.pt\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nstrategy_config = {\n    \"head_type\": \"strategy\",\n    \"dataset\": \"ESConv\",\n    \"num_labels\": NUM_STRATEGIES,\n    \"label_map\": STRATEGY_LABELS,\n    \"pooling\": \"mean_pooled_input_embeddings\",\n    \"hidden_dim\": hidden_dim,\n    \"architecture\": \"LayerNorm â†’ MLP â†’ Linear\"\n}\n\nwith open(\"strategy_head_config.json\", \"w\") as f:\n    json.dump(strategy_config, f, indent=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}